#!/bin/bash
# Jupyter Notebook å•Ÿå‹•è…³æœ¬

set -e

# é¡¯ç¤ºå•Ÿå‹•ä¿¡æ¯
echo "ğŸš€ å•Ÿå‹• Spark101 Jupyter ç’°å¢ƒ..."
echo "ğŸ“Š Java ç‰ˆæœ¬: $(java -version 2>&1 | head -1)"
echo "ğŸ Python ç‰ˆæœ¬: $(python --version)"
echo "âš¡ Spark ç‰ˆæœ¬: $(python -c 'import pyspark; print(pyspark.__version__)')"

# è¨­å®šç’°å¢ƒè®Šæ•¸
export JAVA_HOME=${JAVA_HOME:-/usr/lib/jvm/java-11-openjdk-amd64}
export SPARK_HOME=${SPARK_HOME:-/opt/spark101/.venv/lib/python3.11/site-packages/pyspark}
export PYTHONPATH=/opt/spark101:$PYTHONPATH
export PYSPARK_PYTHON=python
export PYSPARK_DRIVER_PYTHON=python

# å‰µå»ºå¿…è¦çš„ç›®éŒ„
mkdir -p /opt/spark101/logs
mkdir -p /opt/spark101/spark-warehouse
mkdir -p /opt/spark101/tmp

# è¨­å®šæ¬Šé™
chmod -R 755 /opt/spark101/logs
chmod -R 755 /opt/spark101/spark-warehouse

# æ¸¬è©¦ Spark ç’°å¢ƒ
echo "ğŸ§ª æ¸¬è©¦ Spark ç’°å¢ƒ..."
python -c "
import pyspark
from pyspark.sql import SparkSession
try:
    spark = SparkSession.builder.appName('DockerTest').master('local[*]').getOrCreate()
    print('âœ… Spark ç’°å¢ƒæ¸¬è©¦æˆåŠŸ')
    spark.stop()
except Exception as e:
    print(f'âŒ Spark ç’°å¢ƒæ¸¬è©¦å¤±æ•—: {e}')
"

# å•Ÿå‹• Jupyter Notebook
echo "ğŸ““ å•Ÿå‹• Jupyter Notebook..."
echo "ğŸŒ è¨ªå•åœ°å€: http://localhost:8888"
echo "ğŸ” Token: ${JUPYTER_TOKEN:-spark101}"
echo "ğŸ“‚ å·¥ä½œç›®éŒ„: /opt/spark101"

# æª¢æŸ¥æ˜¯å¦è¦å•Ÿå‹• Lab æˆ– Notebook
if [ "${JUPYTER_ENABLE_LAB:-no}" = "yes" ]; then
    echo "ğŸ”¬ å•Ÿå‹• JupyterLab..."
    exec jupyter lab \
        --ip=0.0.0.0 \
        --port=8888 \
        --no-browser \
        --allow-root \
        --NotebookApp.token="${JUPYTER_TOKEN:-spark101}" \
        --NotebookApp.notebook_dir="/opt/spark101"
else
    echo "ğŸ“” å•Ÿå‹• Jupyter Notebook..."
    exec jupyter notebook \
        --ip=0.0.0.0 \
        --port=8888 \
        --no-browser \
        --allow-root \
        --NotebookApp.token="${JUPYTER_TOKEN:-spark101}" \
        --NotebookApp.notebook_dir="/opt/spark101"
fi