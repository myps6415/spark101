#!/usr/bin/env python3
"""
ç¬¬4ç« ï¼šSpark SQL - SQL æŸ¥è©¢åŸºç¤
å­¸ç¿’ Spark SQL çš„åŸºæœ¬èªæ³•å’ŒæŸ¥è©¢æ“ä½œ
"""

from pyspark.sql import SparkSession
from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType, DateType
from pyspark.sql.functions import col, when, desc, asc
from datetime import date

def main():
    # å‰µå»º SparkSession
    spark = SparkSession.builder \
        .appName("Spark SQL Basics") \
        .master("local[*]") \
        .getOrCreate()
    
    print("ğŸ” Spark SQL åŸºç¤æŸ¥è©¢ç¤ºç¯„")
    print("=" * 40)
    
    # æº–å‚™ç¤ºä¾‹æ•¸æ“š
    
    # å“¡å·¥æ•¸æ“š
    employees_data = [
        (1, "Alice", 25, "Engineer", 75000.0, "IT", date(2020, 1, 15)),
        (2, "Bob", 30, "Manager", 85000.0, "Sales", date(2019, 3, 20)),
        (3, "Charlie", 35, "Designer", 65000.0, "Marketing", date(2021, 7, 10)),
        (4, "Diana", 28, "Analyst", 70000.0, "Finance", date(2020, 11, 5)),
        (5, "Eve", 32, "Engineer", 80000.0, "IT", date(2018, 9, 12)),
        (6, "Frank", 29, "Manager", 90000.0, "IT", date(2019, 6, 18)),
        (7, "Grace", 26, "Designer", 62000.0, "Marketing", date(2021, 2, 28)),
        (8, "Henry", 33, "Analyst", 72000.0, "Finance", date(2020, 8, 22))
    ]
    
    employees_schema = StructType([
        StructField("id", IntegerType(), False),
        StructField("name", StringType(), False),
        StructField("age", IntegerType(), True),
        StructField("job", StringType(), True),
        StructField("salary", DoubleType(), True),
        StructField("department", StringType(), True),
        StructField("hire_date", DateType(), True)
    ])
    
    # éƒ¨é–€æ•¸æ“š
    departments_data = [
        ("IT", "Information Technology", "Alice Johnson"),
        ("Sales", "Sales Department", "Bob Wilson"),
        ("Marketing", "Marketing Department", "Charlie Davis"),
        ("Finance", "Finance Department", "Diana Lee")
    ]
    
    departments_schema = StructType([
        StructField("dept_code", StringType(), False),
        StructField("dept_name", StringType(), False),
        StructField("manager", StringType(), True)
    ])
    
    # å‰µå»º DataFrame
    employees_df = spark.createDataFrame(employees_data, employees_schema)
    departments_df = spark.createDataFrame(departments_data, departments_schema)
    
    print("å“¡å·¥æ•¸æ“š:")
    employees_df.show()
    
    print("éƒ¨é–€æ•¸æ“š:")
    departments_df.show()
    
    # 1. å‰µå»ºè‡¨æ™‚è¦–åœ–
    print("\n1ï¸âƒ£ å‰µå»ºè‡¨æ™‚è¦–åœ–")
    
    # å‰µå»ºè‡¨æ™‚è¦–åœ–
    employees_df.createOrReplaceTempView("employees")
    departments_df.createOrReplaceTempView("departments")
    
    print("è‡¨æ™‚è¦–åœ– 'employees' å’Œ 'departments' å·²å‰µå»º")
    
    # 2. åŸºæœ¬ SELECT æŸ¥è©¢
    print("\n2ï¸âƒ£ åŸºæœ¬ SELECT æŸ¥è©¢")
    
    # é¸æ“‡æ‰€æœ‰åˆ—
    result = spark.sql("SELECT * FROM employees")
    print("é¸æ“‡æ‰€æœ‰åˆ—:")
    result.show()
    
    # é¸æ“‡ç‰¹å®šåˆ—
    result = spark.sql("SELECT name, age, salary FROM employees")
    print("é¸æ“‡ç‰¹å®šåˆ—:")
    result.show()
    
    # ä½¿ç”¨åˆ¥å
    result = spark.sql("""
        SELECT name AS employee_name, 
               age AS employee_age,
               salary AS monthly_salary
        FROM employees
    """)
    print("ä½¿ç”¨åˆ¥å:")
    result.show()
    
    # 3. WHERE æ¢ä»¶æŸ¥è©¢
    print("\n3ï¸âƒ£ WHERE æ¢ä»¶æŸ¥è©¢")
    
    # æ•¸å€¼æ¢ä»¶
    result = spark.sql("SELECT * FROM employees WHERE age > 30")
    print("å¹´é½¡å¤§æ–¼ 30 çš„å“¡å·¥:")
    result.show()
    
    # å­—ä¸²æ¢ä»¶
    result = spark.sql("SELECT * FROM employees WHERE department = 'IT'")
    print("IT éƒ¨é–€çš„å“¡å·¥:")
    result.show()
    
    # å¤šæ¢ä»¶æŸ¥è©¢
    result = spark.sql("""
        SELECT * FROM employees 
        WHERE age > 25 AND salary > 70000
    """)
    print("å¹´é½¡å¤§æ–¼ 25 ä¸”è–ªè³‡å¤§æ–¼ 70000 çš„å“¡å·¥:")
    result.show()
    
    # ç¯„åœæŸ¥è©¢
    result = spark.sql("SELECT * FROM employees WHERE salary BETWEEN 65000 AND 80000")
    print("è–ªè³‡åœ¨ 65000-80000 ä¹‹é–“çš„å“¡å·¥:")
    result.show()
    
    # IN æŸ¥è©¢
    result = spark.sql("SELECT * FROM employees WHERE job IN ('Engineer', 'Manager')")
    print("è·ä½æ˜¯ Engineer æˆ– Manager çš„å“¡å·¥:")
    result.show()
    
    # LIKE æŸ¥è©¢
    result = spark.sql("SELECT * FROM employees WHERE name LIKE 'A%'")
    print("å§“åä»¥ 'A' é–‹é ­çš„å“¡å·¥:")
    result.show()
    
    # 4. ORDER BY æ’åº
    print("\n4ï¸âƒ£ ORDER BY æ’åº")
    
    # å‡åºæ’åº
    result = spark.sql("SELECT * FROM employees ORDER BY age ASC")
    print("æŒ‰å¹´é½¡å‡åºæ’åº:")
    result.show()
    
    # é™åºæ’åº
    result = spark.sql("SELECT * FROM employees ORDER BY salary DESC")
    print("æŒ‰è–ªè³‡é™åºæ’åº:")
    result.show()
    
    # å¤šæ¬„ä½æ’åº
    result = spark.sql("SELECT * FROM employees ORDER BY department ASC, salary DESC")
    print("æŒ‰éƒ¨é–€å‡åºã€è–ªè³‡é™åºæ’åº:")
    result.show()
    
    # 5. GROUP BY åˆ†çµ„æŸ¥è©¢
    print("\n5ï¸âƒ£ GROUP BY åˆ†çµ„æŸ¥è©¢")
    
    # æŒ‰éƒ¨é–€åˆ†çµ„çµ±è¨ˆ
    result = spark.sql("""
        SELECT department, 
               COUNT(*) as employee_count,
               AVG(salary) as avg_salary,
               MAX(salary) as max_salary,
               MIN(salary) as min_salary
        FROM employees 
        GROUP BY department
    """)
    print("æŒ‰éƒ¨é–€åˆ†çµ„çµ±è¨ˆ:")
    result.show()
    
    # æŒ‰è·ä½åˆ†çµ„çµ±è¨ˆ
    result = spark.sql("""
        SELECT job,
               COUNT(*) as count,
               AVG(age) as avg_age,
               SUM(salary) as total_salary
        FROM employees
        GROUP BY job
        ORDER BY count DESC
    """)
    print("æŒ‰è·ä½åˆ†çµ„çµ±è¨ˆ:")
    result.show()
    
    # HAVING å­å¥
    result = spark.sql("""
        SELECT department,
               COUNT(*) as employee_count,
               AVG(salary) as avg_salary
        FROM employees
        GROUP BY department
        HAVING COUNT(*) > 1
    """)
    print("å“¡å·¥æ•¸é‡å¤§æ–¼ 1 çš„éƒ¨é–€:")
    result.show()
    
    # 6. JOIN é€£æ¥æŸ¥è©¢
    print("\n6ï¸âƒ£ JOIN é€£æ¥æŸ¥è©¢")
    
    # INNER JOIN
    result = spark.sql("""
        SELECT e.name, e.job, e.salary, d.dept_name
        FROM employees e
        INNER JOIN departments d ON e.department = d.dept_code
    """)
    print("å“¡å·¥å’Œéƒ¨é–€ä¿¡æ¯ (INNER JOIN):")
    result.show()
    
    # LEFT JOIN
    result = spark.sql("""
        SELECT e.name, e.job, e.salary, d.dept_name, d.manager
        FROM employees e
        LEFT JOIN departments d ON e.department = d.dept_code
    """)
    print("å“¡å·¥å’Œéƒ¨é–€ä¿¡æ¯ (LEFT JOIN):")
    result.show()
    
    # 7. å­æŸ¥è©¢
    print("\n7ï¸âƒ£ å­æŸ¥è©¢")
    
    # æ¨™é‡å­æŸ¥è©¢
    result = spark.sql("""
        SELECT name, salary,
               (SELECT AVG(salary) FROM employees) as avg_salary
        FROM employees
        WHERE salary > (SELECT AVG(salary) FROM employees)
    """)
    print("è–ªè³‡é«˜æ–¼å¹³å‡è–ªè³‡çš„å“¡å·¥:")
    result.show()
    
    # ç›¸é—œå­æŸ¥è©¢
    result = spark.sql("""
        SELECT e1.name, e1.department, e1.salary
        FROM employees e1
        WHERE e1.salary = (
            SELECT MAX(e2.salary)
            FROM employees e2
            WHERE e2.department = e1.department
        )
    """)
    print("æ¯å€‹éƒ¨é–€è–ªè³‡æœ€é«˜çš„å“¡å·¥:")
    result.show()
    
    # 8. çª—å£å‡½æ•¸
    print("\n8ï¸âƒ£ çª—å£å‡½æ•¸")
    
    # ROW_NUMBER
    result = spark.sql("""
        SELECT name, department, salary,
               ROW_NUMBER() OVER (PARTITION BY department ORDER BY salary DESC) as rank
        FROM employees
    """)
    print("æŒ‰éƒ¨é–€è–ªè³‡æ’å:")
    result.show()
    
    # RANK å’Œ DENSE_RANK
    result = spark.sql("""
        SELECT name, department, salary,
               RANK() OVER (PARTITION BY department ORDER BY salary DESC) as rank,
               DENSE_RANK() OVER (PARTITION BY department ORDER BY salary DESC) as dense_rank
        FROM employees
    """)
    print("æŒ‰éƒ¨é–€è–ªè³‡æ’å (RANK vs DENSE_RANK):")
    result.show()
    
    # ç´¯è¨ˆçµ±è¨ˆ
    result = spark.sql("""
        SELECT name, department, salary,
               SUM(salary) OVER (PARTITION BY department ORDER BY salary) as cumulative_salary,
               AVG(salary) OVER (PARTITION BY department) as dept_avg_salary
        FROM employees
        ORDER BY department, salary
    """)
    print("ç´¯è¨ˆè–ªè³‡çµ±è¨ˆ:")
    result.show()
    
    # 9. å¸¸ç”¨å‡½æ•¸
    print("\n9ï¸âƒ£ å¸¸ç”¨å‡½æ•¸")
    
    # å­—ä¸²å‡½æ•¸
    result = spark.sql("""
        SELECT name,
               UPPER(name) as upper_name,
               LOWER(name) as lower_name,
               LENGTH(name) as name_length,
               CONCAT(name, ' - ', job) as name_job
        FROM employees
    """)
    print("å­—ä¸²å‡½æ•¸:")
    result.show()
    
    # æ•¸å€¼å‡½æ•¸
    result = spark.sql("""
        SELECT name, salary,
               ROUND(salary / 12, 2) as monthly_salary,
               CEIL(salary / 1000) as salary_k_ceil,
               FLOOR(salary / 1000) as salary_k_floor
        FROM employees
    """)
    print("æ•¸å€¼å‡½æ•¸:")
    result.show()
    
    # æ—¥æœŸå‡½æ•¸
    result = spark.sql("""
        SELECT name, hire_date,
               YEAR(hire_date) as hire_year,
               MONTH(hire_date) as hire_month,
               DAYOFYEAR(hire_date) as day_of_year,
               DATEDIFF(CURRENT_DATE(), hire_date) as days_since_hire
        FROM employees
    """)
    print("æ—¥æœŸå‡½æ•¸:")
    result.show()
    
    # 10. æ¢ä»¶å‡½æ•¸
    print("\nğŸ”Ÿ æ¢ä»¶å‡½æ•¸")
    
    # CASE WHEN
    result = spark.sql("""
        SELECT name, age, salary,
               CASE 
                   WHEN age < 30 THEN 'Young'
                   WHEN age < 35 THEN 'Middle'
                   ELSE 'Senior'
               END as age_group,
               CASE
                   WHEN salary > 80000 THEN 'High'
                   WHEN salary > 70000 THEN 'Medium'
                   ELSE 'Low'
               END as salary_level
        FROM employees
    """)
    print("æ¢ä»¶åˆ†çµ„:")
    result.show()
    
    # IF å‡½æ•¸
    result = spark.sql("""
        SELECT name, salary,
               IF(salary > 75000, 'High Earner', 'Regular') as earner_type
        FROM employees
    """)
    print("IF å‡½æ•¸:")
    result.show()
    
    # 11. é›†åˆæ“ä½œ
    print("\n1ï¸âƒ£1ï¸âƒ£ é›†åˆæ“ä½œ")
    
    # å‰µå»ºå…©å€‹å­é›†ç”¨æ–¼æ¼”ç¤º
    high_earners = spark.sql("SELECT name FROM employees WHERE salary > 75000")
    it_employees = spark.sql("SELECT name FROM employees WHERE department = 'IT'")
    
    # è¨»å†Šç‚ºè‡¨æ™‚è¦–åœ–
    high_earners.createOrReplaceTempView("high_earners")
    it_employees.createOrReplaceTempView("it_employees")
    
    # UNION
    result = spark.sql("""
        SELECT name, 'High Earner' as category FROM high_earners
        UNION ALL
        SELECT name, 'IT Employee' as category FROM it_employees
    """)
    print("UNION æ“ä½œ:")
    result.show()
    
    # INTERSECT
    result = spark.sql("""
        SELECT name FROM high_earners
        INTERSECT
        SELECT name FROM it_employees
    """)
    print("INTERSECT æ“ä½œ (é«˜è–ªä¸”ITéƒ¨é–€):")
    result.show()
    
    # EXCEPT
    result = spark.sql("""
        SELECT name FROM high_earners
        EXCEPT
        SELECT name FROM it_employees
    """)
    print("EXCEPT æ“ä½œ (é«˜è–ªä½†éITéƒ¨é–€):")
    result.show()
    
    # 12. è¤‡é›œæŸ¥è©¢ç¤ºä¾‹
    print("\n1ï¸âƒ£2ï¸âƒ£ è¤‡é›œæŸ¥è©¢ç¤ºä¾‹")
    
    # éƒ¨é–€è–ªè³‡åˆ†æ
    result = spark.sql("""
        WITH dept_stats AS (
            SELECT department,
                   COUNT(*) as emp_count,
                   AVG(salary) as avg_salary,
                   MAX(salary) as max_salary,
                   MIN(salary) as min_salary,
                   STDDEV(salary) as salary_stddev
            FROM employees
            GROUP BY department
        )
        SELECT d.dept_name,
               ds.emp_count,
               ROUND(ds.avg_salary, 2) as avg_salary,
               ds.max_salary,
               ds.min_salary,
               ROUND(ds.salary_stddev, 2) as salary_stddev,
               ds.manager
        FROM dept_stats ds
        JOIN departments d ON ds.department = d.dept_code
        ORDER BY ds.avg_salary DESC
    """)
    print("éƒ¨é–€è–ªè³‡åˆ†æ:")
    result.show()
    
    # å“¡å·¥æ’åå’Œè–ªè³‡å·®ç•°
    result = spark.sql("""
        SELECT name, department, salary,
               RANK() OVER (ORDER BY salary DESC) as overall_rank,
               RANK() OVER (PARTITION BY department ORDER BY salary DESC) as dept_rank,
               salary - AVG(salary) OVER (PARTITION BY department) as salary_diff_from_dept_avg,
               salary - AVG(salary) OVER () as salary_diff_from_overall_avg
        FROM employees
        ORDER BY salary DESC
    """)
    print("å“¡å·¥æ’åå’Œè–ªè³‡å·®ç•°:")
    result.show()
    
    # åœæ­¢ SparkSession
    spark.stop()
    print("\nâœ… Spark SQL åŸºç¤æŸ¥è©¢ç¤ºç¯„å®Œæˆ")

if __name__ == "__main__":
    main()