#!/usr/bin/env python3
"""
ç¬¬3ç« ï¼šDataFrame å’Œ Dataset API - Schema æ“ä½œ
å­¸ç¿’ Schema å®šç¾©ã€é¡å‹è½‰æ›å’Œè³‡æ–™é©—è­‰
"""

from datetime import date, datetime

from pyspark.sql import SparkSession
from pyspark.sql.functions import (cast, col, regexp_extract, to_date,
                                   to_timestamp)
from pyspark.sql.types import (ArrayType, BooleanType, DateType, DoubleType,
                               IntegerType, StringType, StructField,
                               StructType, TimestampType)


def main():
    # å‰µå»º SparkSession
    spark = (
        SparkSession.builder.appName("Schema Operations")
        .master("local[*]")
        .getOrCreate()
    )

    print("ğŸ—ï¸ Schema æ“ä½œç¤ºç¯„")
    print("=" * 40)

    # 1. å®šç¾©è¤‡é›œ Schema
    print("\n1ï¸âƒ£ å®šç¾©è¤‡é›œ Schema")

    # å®šç¾©åµŒå¥—çš„ Schema
    address_schema = StructType(
        [
            StructField("street", StringType(), True),
            StructField("city", StringType(), True),
            StructField("zipcode", StringType(), True),
        ]
    )

    employee_schema = StructType(
        [
            StructField("id", IntegerType(), False),
            StructField("name", StringType(), False),
            StructField("age", IntegerType(), True),
            StructField("salary", DoubleType(), True),
            StructField("is_active", BooleanType(), True),
            StructField("hire_date", DateType(), True),
            StructField("last_login", TimestampType(), True),
            StructField("skills", ArrayType(StringType()), True),
            StructField("address", address_schema, True),
        ]
    )

    print("å“¡å·¥ Schema çµæ§‹:")
    print(employee_schema)

    # 2. ä½¿ç”¨ Schema å‰µå»º DataFrame
    print("\n2ï¸âƒ£ ä½¿ç”¨ Schema å‰µå»º DataFrame")

    # æº–å‚™è¤‡é›œæ•¸æ“š
    complex_data = [
        (
            1,
            "Alice",
            25,
            75000.0,
            True,
            date(2020, 1, 15),
            datetime(2024, 1, 10, 9, 30, 0),
            ["Python", "Spark", "SQL"],
            ("123 Main St", "New York", "10001"),
        ),
        (
            2,
            "Bob",
            30,
            85000.0,
            True,
            date(2019, 3, 20),
            datetime(2024, 1, 9, 14, 45, 0),
            ["Java", "Scala", "Kafka"],
            ("456 Oak Ave", "Boston", "02101"),
        ),
        (
            3,
            "Charlie",
            35,
            65000.0,
            False,
            date(2021, 7, 10),
            datetime(2024, 1, 8, 11, 20, 0),
            ["JavaScript", "React", "Node.js"],
            ("789 Pine Rd", "Seattle", "98101"),
        ),
    ]

    df = spark.createDataFrame(complex_data, employee_schema)
    print("è¤‡é›œ DataFrame:")
    df.show(truncate=False)

    print("\nDataFrame Schema:")
    df.printSchema()

    # 3. Schema é©—è­‰å’Œæª¢æŸ¥
    print("\n3ï¸âƒ£ Schema é©—è­‰å’Œæª¢æŸ¥")

    # æª¢æŸ¥åˆ—æ˜¯å¦å­˜åœ¨
    required_columns = ["id", "name", "salary"]
    for col_name in required_columns:
        if col_name in df.columns:
            print(f"âœ… åˆ— '{col_name}' å­˜åœ¨")
        else:
            print(f"âŒ åˆ— '{col_name}' ä¸å­˜åœ¨")

    # æª¢æŸ¥è³‡æ–™é¡å‹
    print("\nåˆ—çš„è³‡æ–™é¡å‹:")
    for field in df.schema.fields:
        print(f"  {field.name}: {field.dataType}")

    # æª¢æŸ¥ç©ºå€¼ç´„æŸ
    print("\nç©ºå€¼ç´„æŸ:")
    for field in df.schema.fields:
        nullable = "å¯ç©º" if field.nullable else "ä¸å¯ç©º"
        print(f"  {field.name}: {nullable}")

    # 4. é¡å‹è½‰æ›
    print("\n4ï¸âƒ£ é¡å‹è½‰æ›")

    # å­—ä¸²è½‰æ•¸å­—
    string_data = [
        ("1", "Alice", "25", "75000.50"),
        ("2", "Bob", "30", "85000.75"),
        ("3", "Charlie", "35", "65000.25"),
    ]

    string_df = spark.createDataFrame(
        string_data, ["id_str", "name", "age_str", "salary_str"]
    )
    print("å­—ä¸²æ ¼å¼çš„ DataFrame:")
    string_df.show()
    string_df.printSchema()

    # è½‰æ›è³‡æ–™é¡å‹
    converted_df = string_df.select(
        cast(col("id_str"), IntegerType()).alias("id"),
        col("name"),
        cast(col("age_str"), IntegerType()).alias("age"),
        cast(col("salary_str"), DoubleType()).alias("salary"),
    )

    print("è½‰æ›å¾Œçš„ DataFrame:")
    converted_df.show()
    converted_df.printSchema()

    # 5. æ—¥æœŸæ™‚é–“è™•ç†
    print("\n5ï¸âƒ£ æ—¥æœŸæ™‚é–“è™•ç†")

    # å­—ä¸²è½‰æ—¥æœŸ
    date_data = [
        ("Alice", "2020-01-15", "2024-01-10 09:30:00"),
        ("Bob", "2019-03-20", "2024-01-09 14:45:00"),
        ("Charlie", "2021-07-10", "2024-01-08 11:20:00"),
    ]

    date_df = spark.createDataFrame(
        date_data, ["name", "hire_date_str", "last_login_str"]
    )
    print("å­—ä¸²æ ¼å¼çš„æ—¥æœŸ DataFrame:")
    date_df.show()

    # è½‰æ›æ—¥æœŸæ ¼å¼
    date_converted_df = date_df.select(
        col("name"),
        to_date(col("hire_date_str"), "yyyy-MM-dd").alias("hire_date"),
        to_timestamp(col("last_login_str"), "yyyy-MM-dd HH:mm:ss").alias("last_login"),
    )

    print("è½‰æ›å¾Œçš„æ—¥æœŸ DataFrame:")
    date_converted_df.show()
    date_converted_df.printSchema()

    # 6. å¾æ–‡æœ¬ä¸­æå–çµæ§‹åŒ–è³‡æ–™
    print("\n6ï¸âƒ£ å¾æ–‡æœ¬ä¸­æå–çµæ§‹åŒ–è³‡æ–™")

    # åŒ…å«éçµæ§‹åŒ–æ–‡æœ¬çš„æ•¸æ“š
    text_data = [
        ("user001", "Name: Alice Johnson, Age: 25, Email: alice@example.com"),
        ("user002", "Name: Bob Smith, Age: 30, Email: bob@example.com"),
        ("user003", "Name: Charlie Brown, Age: 35, Email: charlie@example.com"),
    ]

    text_df = spark.createDataFrame(text_data, ["user_id", "info"])
    print("åŒ…å«éçµæ§‹åŒ–æ–‡æœ¬çš„ DataFrame:")
    text_df.show(truncate=False)

    # ä½¿ç”¨æ­£å‰‡è¡¨é”å¼æå–ä¿¡æ¯
    extracted_df = text_df.select(
        col("user_id"),
        regexp_extract(col("info"), r"Name: ([^,]+)", 1).alias("name"),
        regexp_extract(col("info"), r"Age: (\d+)", 1).cast(IntegerType()).alias("age"),
        regexp_extract(col("info"), r"Email: ([^\s]+)", 1).alias("email"),
    )

    print("æå–å¾Œçš„çµæ§‹åŒ– DataFrame:")
    extracted_df.show()
    extracted_df.printSchema()

    # 7. Schema æ¼”åŒ–å’Œç›¸å®¹æ€§
    print("\n7ï¸âƒ£ Schema æ¼”åŒ–å’Œç›¸å®¹æ€§")

    # åŸå§‹ Schema
    old_schema = StructType(
        [
            StructField("id", IntegerType(), False),
            StructField("name", StringType(), False),
            StructField("age", IntegerType(), True),
        ]
    )

    # æ–° Schema (æ·»åŠ äº†æ¬„ä½)
    new_schema = StructType(
        [
            StructField("id", IntegerType(), False),
            StructField("name", StringType(), False),
            StructField("age", IntegerType(), True),
            StructField("department", StringType(), True),  # æ–°å¢æ¬„ä½
            StructField("salary", DoubleType(), True),  # æ–°å¢æ¬„ä½
        ]
    )

    # èˆŠæ ¼å¼æ•¸æ“š
    old_data = [(1, "Alice", 25), (2, "Bob", 30)]
    old_df = spark.createDataFrame(old_data, old_schema)

    print("èˆŠæ ¼å¼ DataFrame:")
    old_df.show()

    # ä½¿æ–°èˆŠæ ¼å¼ç›¸å®¹
    from pyspark.sql.functions import lit

    compatible_df = old_df.select(
        col("id"),
        col("name"),
        col("age"),
        lit(None).cast(StringType()).alias("department"),
        lit(None).cast(DoubleType()).alias("salary"),
    )

    print("ç›¸å®¹æ€§èª¿æ•´å¾Œçš„ DataFrame:")
    compatible_df.show()
    compatible_df.printSchema()

    # 8. å‹•æ…‹ Schema æ“ä½œ
    print("\n8ï¸âƒ£ å‹•æ…‹ Schema æ“ä½œ")

    # å‹•æ…‹æ·»åŠ åˆ—
    dynamic_df = df.select("id", "name", "age", "salary")

    # æ ¹æ“šæ¢ä»¶å‹•æ…‹æ·»åŠ åˆ—
    columns_to_add = ["bonus", "tax", "net_salary"]

    for col_name in columns_to_add:
        if col_name == "bonus":
            dynamic_df = dynamic_df.withColumn(col_name, col("salary") * 0.1)
        elif col_name == "tax":
            dynamic_df = dynamic_df.withColumn(col_name, col("salary") * 0.25)
        elif col_name == "net_salary":
            dynamic_df = dynamic_df.withColumn(
                col_name, col("salary") - col("tax") + col("bonus")
            )

    print("å‹•æ…‹æ·»åŠ åˆ—å¾Œçš„ DataFrame:")
    dynamic_df.show()

    # åœæ­¢ SparkSession
    spark.stop()
    print("\nâœ… Schema æ“ä½œç¤ºç¯„å®Œæˆ")


if __name__ == "__main__":
    main()
