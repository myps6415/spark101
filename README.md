# ğŸ”¥ Spark 101 æ•™å­¸èª²ç¨‹

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![Apache Spark 3.4+](https://img.shields.io/badge/Spark-3.4+-orange.svg)](https://spark.apache.org/)
[![Poetry](https://img.shields.io/badge/dependency--manager-poetry-blue)](https://python-poetry.org/)
[![Tests](https://img.shields.io/badge/tests-passing-brightgreen.svg)](./tests/)

> ğŸ¯ **å¾é›¶é–‹å§‹å­¸ç¿’ Apache Spark çš„å®Œæ•´æ•™å­¸è³‡æº**

ä¸€å€‹å…¨é¢ã€å¯¦æˆ°å°å‘çš„ Apache Spark å­¸ç¿’é …ç›®ï¼ŒåŒ…å«å®Œæ•´çš„æ•™å­¸å…§å®¹ã€å¯¦ä½œç·´ç¿’ã€ä¼æ¥­ç´šé …ç›®å’Œæ¸¬è©¦å¥—ä»¶ã€‚

## ğŸ“Š å°ˆæ¡ˆç‰¹è‰²

- âœ… **32å€‹å¯¦ä½œç·´ç¿’** - æ¯ç« 4å€‹å¾ªåºæ¼¸é€²çš„ç·´ç¿’
- âœ… **8å€‹äº’å‹•å¼ Notebook** - è±å¯Œçš„å­¸ç¿’é«”é©—
- âœ… **3å€‹ä¼æ¥­ç´šå¯¦æˆ°é …ç›®** - æ—¥èªŒåˆ†æã€ç›£æ§ç³»çµ±ã€æ¨è–¦ç³»çµ±
- âœ… **å®Œæ•´æ¸¬è©¦å¥—ä»¶** - 10å€‹æ¸¬è©¦æ–‡ä»¶ï¼Œå…¨é¢è¦†è“‹
- âœ… **ä¸­æ–‡æ–‡æª”** - é©åˆè¯èªå­¸ç¿’è€…
- âœ… **è‡ªå‹•åŒ–å·¥å…·** - ä¸€éµç’°å¢ƒè¨­ç½®å’Œé …ç›®ç®¡ç†

## ğŸ¯ å­¸ç¿’ç›®æ¨™

- ğŸ’ª æŒæ¡ Apache Spark çš„æ ¸å¿ƒæ¦‚å¿µå’Œæ¶æ§‹
- ğŸ”§ ç†Ÿç·´ä½¿ç”¨ Spark Core, DataFrame, SQL ç­‰ API
- ğŸ“Š å­¸æœƒ Spark Streaming å³æ™‚æ•¸æ“šè™•ç†
- ğŸ¤– äº†è§£ MLlib æ©Ÿå™¨å­¸ç¿’æ‡‰ç”¨
- âš¡ æŒæ¡æ€§èƒ½èª¿å„ªæŠ€å·§
- ğŸš€ å®Œæˆä¼æ¥­ç´šå¯¦æˆ°é …ç›®

## ğŸ“š èª²ç¨‹å¤§ç¶±

### ğŸŒŸ åŸºç¤ç¯‡

| ç« ç¯€ | ä¸»é¡Œ | ç¯„ä¾‹ | ç·´ç¿’ | é‡é»å…§å®¹ |
|------|------|------|------|----------|
| **ç¬¬1ç« ** | Spark åŸºç¤æ¦‚å¿µ | 1 | 4 | ç’°å¢ƒè¨­ç½®ã€ç¬¬ä¸€å€‹ç¨‹å¼ã€æ ¸å¿ƒæ¶æ§‹ |
| **ç¬¬2ç« ** | RDD åŸºæœ¬æ“ä½œ | 1 | 4 | RDDæ¦‚å¿µã€è½‰æ›æ“ä½œã€è¡Œå‹•æ“ä½œ |
| **ç¬¬3ç« ** | DataFrame API | 3 | 4 | Schemaå®šç¾©ã€æ•¸æ“šè®€å¯«ã€åŸºæœ¬æ“ä½œ |

### ğŸ”¥ é€²éšç¯‡

| ç« ç¯€ | ä¸»é¡Œ | ç¯„ä¾‹ | ç·´ç¿’ | é‡é»å…§å®¹ |
|------|------|------|------|----------|
| **ç¬¬4ç« ** | Spark SQL | 2 | 4 | SQLæŸ¥è©¢ã€è¦–çª—å‡½æ•¸ã€è¤‡é›œåˆ†æ |
| **ç¬¬5ç« ** | Spark Streaming | 2 | 4 | çµæ§‹åŒ–æµã€å¯¦æ™‚è™•ç†ã€ç‹€æ…‹ç®¡ç† |
| **ç¬¬6ç« ** | MLlib æ©Ÿå™¨å­¸ç¿’ | 1 | 4 | ç‰¹å¾µå·¥ç¨‹ã€æ¨¡å‹è¨“ç·´ã€ç®¡é“æ§‹å»º |

### ğŸš€ å¯¦æˆ°ç¯‡

| ç« ç¯€ | ä¸»é¡Œ | ç¯„ä¾‹ | ç·´ç¿’ | é‡é»å…§å®¹ |
|------|------|------|------|----------|
| **ç¬¬7ç« ** | æ€§èƒ½èª¿å„ª | 1 | 4 | åˆ†å€ç­–ç•¥ã€ç·©å­˜å„ªåŒ–ã€è³‡æºç®¡ç† |
| **ç¬¬8ç« ** | å¯¦æˆ°é …ç›® | 2 | 4 | æ—¥èªŒåˆ†æã€æ¨è–¦ç³»çµ±ã€ç¶œåˆå¹³å° |

## ğŸ› ï¸ ç’°å¢ƒè¦æ±‚

### ç³»çµ±éœ€æ±‚
- **Java**: 8 æˆ– 11 (æ¨è–¦ OpenJDK 11)
- **Python**: 3.8+ 
- **è¨˜æ†¶é«”**: è‡³å°‘ 4GB RAM
- **ä½œæ¥­ç³»çµ±**: Linux, macOS, Windows

### ä¸»è¦ä¾è³´
- **Apache Spark**: 3.4.1
- **Python å¥—ä»¶**: pandas, numpy, jupyter
- **é–‹ç™¼å·¥å…·**: pytest, poetry

## ğŸ“¦ å¿«é€Ÿå®‰è£

### æ–¹æ³•ä¸€ï¼šPoetry (æ¨è–¦)

```bash
# 1. å…‹éš†å°ˆæ¡ˆ
git clone https://github.com/myps6415/spark101.git
cd spark101

# 2. å®‰è£ Poetry (å¦‚æœå°šæœªå®‰è£)
curl -sSL https://install.python-poetry.org | python3 -

# 3. å®‰è£ä¾è³´ä¸¦åˆå§‹åŒ–ç’°å¢ƒ
make bootstrap
# æˆ–åˆ†æ­¥åŸ·è¡Œï¼š
# poetry install
# poetry run python scripts/bootstrap.py

# 4. æ¿€æ´»ç’°å¢ƒ
poetry shell
```

### æ–¹æ³•äºŒï¼šå‚³çµ± pip å®‰è£

```bash
# 1. å…‹éš†å°ˆæ¡ˆ
git clone https://github.com/myps6415/spark101.git
cd spark101

# 2. å»ºç«‹è™›æ“¬ç’°å¢ƒ
python -m venv venv
source venv/bin/activate  # Linux/macOS
# æˆ– venv\Scripts\activate  # Windows

# 3. å®‰è£ä¾è³´
pip install -r requirements.txt

# 4. æ¸¬è©¦ç’°å¢ƒ
python test_spark_setup.py
```

### æ–¹æ³•ä¸‰ï¼šDocker (æ¨è–¦ï¼Œçµ±ä¸€ç’°å¢ƒ)

#### ğŸ³ å®Œæ•´ç’°å¢ƒï¼ˆåŒ…å«æ‰€æœ‰æœå‹™ï¼‰
```bash
# 1. å…‹éš†å°ˆæ¡ˆ
git clone https://github.com/myps6415/spark101.git
cd spark101

# 2. å•Ÿå‹•å®Œæ•´ç’°å¢ƒ
docker-compose up -d

# 3. è¨ªå• Jupyter Notebook
open http://localhost:8888
# Token: spark101
```

#### ğŸ”§ é–‹ç™¼ç’°å¢ƒï¼ˆè¼•é‡ç´šï¼‰
```bash
# å•Ÿå‹•é–‹ç™¼ç’°å¢ƒ
docker-compose -f docker-compose.dev.yml up -d

# æŸ¥çœ‹ç‹€æ…‹
docker-compose -f docker-compose.dev.yml ps

# é€²å…¥å®¹å™¨
docker-compose -f docker-compose.dev.yml exec spark101-dev bash
```

#### ğŸ› ï¸ VS Code é–‹ç™¼å®¹å™¨
```bash
# 1. å®‰è£ VS Code å’Œ Remote-Containers æ“´å±•
# 2. åœ¨ VS Code ä¸­é–‹å•Ÿå°ˆæ¡ˆ
# 3. æŒ‰ Ctrl+Shift+Pï¼Œé¸æ“‡ "Remote-Containers: Reopen in Container"
# 4. é¸æ“‡ "From 'docker-compose.yml'"
```

#### ğŸ¯ Docker ç’°å¢ƒèªªæ˜
- **ğŸ”¥ Spark101 ä¸»ç’°å¢ƒ**: Jupyter Notebook + PySpark 3.4.1 + Java 11
- **ğŸ—„ï¸ PostgreSQL**: ç”¨æ–¼è³‡æ–™åº«ç›¸é—œç·´ç¿’
- **ğŸ”´ Redis**: ç”¨æ–¼å¿«å–å’Œæµè™•ç†ç·´ç¿’
- **ğŸ“Š Kafka**: ç”¨æ–¼æµè™•ç†å’Œè¨Šæ¯ä½‡åˆ—ç·´ç¿’
- **ğŸ’¾ Minio**: S3 ç›¸å®¹çš„ç‰©ä»¶å„²å­˜
- **ğŸ“ˆ Prometheus + Grafana**: ç›£æ§å’Œè¦–è¦ºåŒ–
- **ğŸ–¥ï¸ åŸ è™Ÿå°æ‡‰**:
  - Jupyter Notebook: http://localhost:8888
  - Spark UI: http://localhost:4040
  - Grafana: http://localhost:3000
  - Prometheus: http://localhost:9090
  - Minio: http://localhost:9000

#### ğŸš€ ä¸€éµå•Ÿå‹•è…³æœ¬
```bash
# å¿«é€Ÿå•Ÿå‹•é–‹ç™¼ç’°å¢ƒ
chmod +x scripts/setup_java_env.sh
./scripts/setup_java_env.sh

# æˆ–è€…ä½¿ç”¨ Docker
make docker-up
```

> ğŸ“– **è©³ç´°çš„ Docker ä½¿ç”¨æŒ‡å—**: [DOCKER_GUIDE.md](./DOCKER_GUIDE.md) - åŒ…å«å®Œæ•´çš„ Docker ç’°å¢ƒè¨­ç½®ã€æ•…éšœæ’é™¤å’Œæœ€ä½³å¯¦è¸

## ğŸš€ å¿«é€Ÿé–‹å§‹

### é‹è¡Œç¬¬ä¸€å€‹ç¯„ä¾‹

```bash
# ä½¿ç”¨ Makefile (æ¨è–¦)
make run-examples

# æˆ–ç›´æ¥é‹è¡Œ
poetry run python examples/chapter01/hello_spark.py
```

### å•Ÿå‹• Jupyter Notebook

```bash
# å•Ÿå‹• Jupyter
make jupyter

# æˆ–ç›´æ¥é‹è¡Œ
poetry run jupyter notebook notebooks/
```

### é‹è¡Œæ¸¬è©¦

```bash
# é‹è¡Œæ‰€æœ‰æ¸¬è©¦
make test

# é‹è¡Œç‰¹å®šç« ç¯€æ¸¬è©¦
make test-chapter01

# é‹è¡Œç‰¹å®šæ¸¬è©¦æ–‡ä»¶
poetry run pytest tests/test_chapter01.py -v
```

## ğŸ—‚ï¸ å°ˆæ¡ˆçµæ§‹

```
spark101/
â”œâ”€â”€ ğŸ“„ README.md                    # å°ˆæ¡ˆèªªæ˜
â”œâ”€â”€ âš™ï¸ pyproject.toml              # Poetry é…ç½®
â”œâ”€â”€ ğŸ”§ Makefile                    # è‡ªå‹•åŒ–å‘½ä»¤
â”œâ”€â”€ ğŸ“¦ requirements.txt            # pip ä¾è³´åˆ—è¡¨
â”œâ”€â”€ ğŸ› ï¸ setup_env.py               # ç’°å¢ƒè¨­ç½®è…³æœ¬
â”œâ”€â”€ ğŸ§ª test_spark_setup.py        # ç’°å¢ƒæ¸¬è©¦è…³æœ¬
â”œâ”€â”€ ğŸ“ scripts/
â”‚   â””â”€â”€ ğŸš€ bootstrap.py           # åˆå§‹åŒ–è…³æœ¬
â”œâ”€â”€ ğŸ“š examples/                   # æ•™å­¸ç¯„ä¾‹ (12å€‹æª”æ¡ˆ)
â”‚   â”œâ”€â”€ ğŸ“– chapter01/             # åŸºç¤æ¦‚å¿µ
â”‚   â”œâ”€â”€ ğŸ“– chapter02/             # RDD æ“ä½œ
â”‚   â”œâ”€â”€ ğŸ“– chapter03/             # DataFrame API
â”‚   â”œâ”€â”€ ğŸ“– chapter04/             # Spark SQL
â”‚   â”œâ”€â”€ ğŸ“– chapter05/             # Streaming
â”‚   â”œâ”€â”€ ğŸ“– chapter06/             # MLlib
â”‚   â”œâ”€â”€ ğŸ“– chapter07/             # æ€§èƒ½èª¿å„ª
â”‚   â””â”€â”€ ğŸ“– chapter08/             # å¯¦æˆ°é …ç›®
â”œâ”€â”€ ğŸ’ª exercises/                  # å¯¦ä½œç·´ç¿’ (32å€‹æª”æ¡ˆ)
â”‚   â”œâ”€â”€ ğŸ“ chapter01/             # 4å€‹åŸºç¤ç·´ç¿’
â”‚   â”œâ”€â”€ ğŸ“ chapter02/             # 4å€‹RDDç·´ç¿’
â”‚   â”œâ”€â”€ ğŸ“ chapter03/             # 4å€‹DataFrameç·´ç¿’
â”‚   â”œâ”€â”€ ğŸ“ chapter04/             # 4å€‹SQLç·´ç¿’
â”‚   â”œâ”€â”€ ğŸ“ chapter05/             # 4å€‹Streamingç·´ç¿’
â”‚   â”œâ”€â”€ ğŸ“ chapter06/             # 4å€‹MLlibç·´ç¿’
â”‚   â”œâ”€â”€ ğŸ“ chapter07/             # 4å€‹èª¿å„ªç·´ç¿’
â”‚   â””â”€â”€ ğŸ“ chapter08/             # 4å€‹é …ç›®ç·´ç¿’
â”œâ”€â”€ ğŸ““ notebooks/                  # Jupyter ç­†è¨˜æœ¬ (8å€‹æª”æ¡ˆ)
â”‚   â”œâ”€â”€ 01_spark_basics.ipynb
â”‚   â”œâ”€â”€ 02_rdd_operations.ipynb
â”‚   â”œâ”€â”€ 03_dataframe_operations.ipynb
â”‚   â”œâ”€â”€ 04_spark_sql.ipynb
â”‚   â”œâ”€â”€ 05_streaming.ipynb
â”‚   â”œâ”€â”€ 06_mllib.ipynb
â”‚   â”œâ”€â”€ 07_performance_tuning.ipynb
â”‚   â””â”€â”€ 08_projects.ipynb
â”œâ”€â”€ ğŸ“Š datasets/                   # ç¤ºä¾‹æ•¸æ“šé›†
â”‚   â”œâ”€â”€ employees_large.csv
â”‚   â”œâ”€â”€ sales_data.json
â”‚   â”œâ”€â”€ sample_data.csv
â”‚   â””â”€â”€ server_logs.txt
â”œâ”€â”€ ğŸ—ï¸ projects/                   # ä¼æ¥­ç´šå¯¦æˆ°é …ç›®
â”‚   â”œâ”€â”€ ğŸ“ˆ log_analyzer/          # æ—¥èªŒåˆ†æç³»çµ±
â”‚   â”œâ”€â”€ ğŸ“Š monitoring_system/     # ç›£æ§ç³»çµ±
â”‚   â””â”€â”€ ğŸ¯ recommendation_system/ # æ¨è–¦ç³»çµ±
â”œâ”€â”€ ğŸ§ª tests/                      # æ¸¬è©¦å¥—ä»¶ (10å€‹æª”æ¡ˆ)
â”‚   â”œâ”€â”€ conftest.py               # æ¸¬è©¦é…ç½®
â”‚   â”œâ”€â”€ test_chapter01.py         # ç¬¬1ç« æ¸¬è©¦
â”‚   â”œâ”€â”€ test_chapter02.py         # ç¬¬2ç« æ¸¬è©¦
â”‚   â”œâ”€â”€ test_chapter03.py         # æ•¸æ“šIOæ¸¬è©¦
â”‚   â”œâ”€â”€ test_chapter04.py         # SQLæ¸¬è©¦
â”‚   â”œâ”€â”€ test_chapter05.py         # Streamingæ¸¬è©¦
â”‚   â”œâ”€â”€ test_chapter06.py         # MLlibæ¸¬è©¦
â”‚   â”œâ”€â”€ test_chapter07.py         # æ€§èƒ½æ¸¬è©¦
â”‚   â”œâ”€â”€ test_chapter08.py         # é …ç›®æ¸¬è©¦
â”‚   â”œâ”€â”€ test_dataframe_operations.py
â”‚   â””â”€â”€ test_projects.py          # é›†æˆæ¸¬è©¦
â””â”€â”€ âš™ï¸ conf/                       # é…ç½®æ–‡ä»¶
    â”œâ”€â”€ spark-defaults.conf       # Spark é…ç½®
    â””â”€â”€ log4j.properties          # æ—¥èªŒé…ç½®
```

## ğŸ”§ å°ˆæ¡ˆç®¡ç†å‘½ä»¤

ä½¿ç”¨ Makefile ç°¡åŒ–æ—¥å¸¸æ“ä½œï¼š

```bash
# ğŸ“š ç’°å¢ƒç®¡ç†
make install      # å®‰è£ä¾è³´
make dev          # è¨­ç½®é–‹ç™¼ç’°å¢ƒ  
make bootstrap    # å®Œæ•´åˆå§‹åŒ–
make clean        # æ¸…ç†ç’°å¢ƒ

# ğŸš€ é‹è¡Œç¯„ä¾‹
make run-examples       # é‹è¡Œç¬¬1ç« ç¯„ä¾‹
make run-chapter01      # é‹è¡Œç¬¬1ç« ç¯„ä¾‹
make run-chapter02      # é‹è¡Œç¬¬2ç« ç¯„ä¾‹
make validate          # é©—è­‰æ‰€æœ‰ç¯„ä¾‹

# ğŸ§ª æ¸¬è©¦
make test              # é‹è¡Œæ‰€æœ‰æ¸¬è©¦
make test-chapter01    # é‹è¡Œç¬¬1ç« æ¸¬è©¦
make test-dataframe    # é‹è¡ŒDataFrameæ¸¬è©¦

# ğŸ““ Jupyter
make jupyter           # å•Ÿå‹• Jupyter Notebook
make jupyterlab        # å•Ÿå‹• JupyterLab

# ğŸ› ï¸ é–‹ç™¼å·¥å…·
make format           # æ ¼å¼åŒ–ä»£ç¢¼
make lint            # ä»£ç¢¼æª¢æŸ¥
make check-env       # æª¢æŸ¥ç’°å¢ƒ
make stats           # å°ˆæ¡ˆçµ±è¨ˆ

make help            # é¡¯ç¤ºæ‰€æœ‰å‘½ä»¤
```

## ğŸ“ å­¸ç¿’è·¯å¾‘å»ºè­°

### ğŸš¶â€â™‚ï¸ åˆå­¸è€… (4-6é€±)
1. **ç¬¬1-2ç« **: äº†è§£åŸºç¤æ¦‚å¿µå’ŒRDDæ“ä½œ
2. **ç¬¬3ç« **: æŒæ¡DataFrame APIçš„ä½¿ç”¨
3. **ç¬¬4ç« **: å­¸ç¿’Spark SQLåŸºæœ¬æŸ¥è©¢
4. **å¯¦ä½œ**: å®ŒæˆåŸºç¤ç·´ç¿’ä¸¦é‹è¡Œæ¸¬è©¦

### ğŸƒâ€â™‚ï¸ é€²éšå­¸ç¿’è€… (3-4é€±)
1. **ç¬¬5ç« **: æ·±å…¥Streamingå¯¦æ™‚è™•ç†
2. **ç¬¬6ç« **: æŒæ¡MLlibæ©Ÿå™¨å­¸ç¿’
3. **ç¬¬7ç« **: å­¸ç¿’æ€§èƒ½èª¿å„ªæŠ€å·§
4. **å¯¦æˆ°**: å®Œæˆä¼æ¥­ç´šé …ç›®ç·´ç¿’

### ğŸš€ å°ˆå®¶ç´š (2-3é€±)
1. **ç¬¬8ç« **: å®Œæˆç¶œåˆå¯¦æˆ°é …ç›®
2. **æ·±åº¦**: ç ”è®€æºç¢¼å’Œé€²éšé…ç½®
3. **è²¢ç»**: åƒèˆ‡é–‹æºé …ç›®è²¢ç»
4. **åˆ†äº«**: å¯«æŠ€è¡“æ–‡ç« æˆ–åšåˆ†äº«

## ğŸ† ä¼æ¥­ç´šå¯¦æˆ°é …ç›®

### 1. ğŸ“ˆ æ—¥èªŒåˆ†æç³»çµ±
- **åŠŸèƒ½**: å¯¦æ™‚æ—¥èªŒç›£æ§ã€ç•°å¸¸æª¢æ¸¬ã€æ€§èƒ½åˆ†æ
- **æŠ€è¡“**: Spark Streaming, æ­£è¦è¡¨é”å¼, çµ±è¨ˆåˆ†æ
- **æ‡‰ç”¨**: ç¶²ç«™ç›£æ§ã€å®‰å…¨åˆ†æã€é‹ç¶­å‘Šè­¦

### 2. ğŸ“Š ç›£æ§ç³»çµ±
- **åŠŸèƒ½**: ç³»çµ±æŒ‡æ¨™æ”¶é›†ã€é–¾å€¼å‘Šè­¦ã€è¶¨å‹¢åˆ†æ
- **æŠ€è¡“**: æ™‚é–“åºåˆ—åˆ†æ, ç•°å¸¸æª¢æ¸¬, å¯¦æ™‚å„€è¡¨æ¿
- **æ‡‰ç”¨**: æœå‹™å™¨ç›£æ§ã€æ‡‰ç”¨æ€§èƒ½ç®¡ç†

### 3. ğŸ¯ æ¨è–¦ç³»çµ±
- **åŠŸèƒ½**: å”åŒéæ¿¾ã€å…§å®¹æ¨è–¦ã€å€‹æ€§åŒ–æ’åº
- **æŠ€è¡“**: ALSç®—æ³•, æ©Ÿå™¨å­¸ç¿’ç®¡é“, A/Bæ¸¬è©¦
- **æ‡‰ç”¨**: é›»å•†æ¨è–¦ã€å…§å®¹æ¨è–¦ã€å»£å‘ŠæŠ•æ”¾

### 4. ğŸ¢ ç¶œåˆæ•¸æ“šå¹³å°
- **åŠŸèƒ½**: æ‰¹æµä¸€é«”ã€æ©Ÿå™¨å­¸ç¿’ã€ç›£æ§å‘Šè­¦
- **æŠ€è¡“**: ç«¯åˆ°ç«¯æ•¸æ“šç®¡é“ã€æ¨¡å‹éƒ¨ç½²ã€è‡ªå‹•åŒ–é‹ç¶­
- **æ‡‰ç”¨**: ä¼æ¥­ç´šæ•¸æ“šå¹³å°ã€æ™ºèƒ½æ±ºç­–ç³»çµ±

## ğŸ§ª æ¸¬è©¦èˆ‡å“è³ªä¿è­‰

### æ¸¬è©¦è¦†è“‹ç¯„åœ
- âœ… **å–®å…ƒæ¸¬è©¦**: æ ¸å¿ƒåŠŸèƒ½æ¸¬è©¦
- âœ… **é›†æˆæ¸¬è©¦**: ç«¯åˆ°ç«¯æµç¨‹æ¸¬è©¦  
- âœ… **æ€§èƒ½æ¸¬è©¦**: å¤§æ•¸æ“šè™•ç†æ¸¬è©¦
- âœ… **é …ç›®æ¸¬è©¦**: å¯¦æˆ°é …ç›®åŠŸèƒ½æ¸¬è©¦

### é‹è¡Œæ¸¬è©¦
```bash
# é‹è¡Œæ‰€æœ‰æ¸¬è©¦
pytest tests/ -v

# é‹è¡Œç‰¹å®šæ¸¬è©¦
pytest tests/test_chapter01.py -v

# æ¸¬è©¦è¦†è“‹ç‡
pytest tests/ --cov=. --cov-report=html
```

## â“ å¸¸è¦‹å•é¡Œ

<details>
<summary><strong>Q: æˆ‘éœ€è¦ä»€éº¼åŸºç¤çŸ¥è­˜ï¼Ÿ</strong></summary>

**å»ºè­°å…·å‚™ï¼š**
- åŸºæœ¬ç¨‹å¼è¨­è¨ˆèƒ½åŠ› (Python/Scala/Java)
- è³‡æ–™åº«å’Œ SQL åŸºç¤
- å°åˆ†æ•£å¼ç³»çµ±æœ‰åŸºæœ¬äº†è§£
- Linux å‘½ä»¤åˆ—åŸºæœ¬æ“ä½œ

**æ¨è–¦å­¸ç¿’è³‡æºï¼š**
- Python: [å»–é›ªå³°çš„Pythonæ•™ç¨‹](https://www.liaoxuefeng.com/wiki/1016959663602400)
- SQL: [W3Schools SQL Tutorial](https://www.w3schools.com/sql/)
- åˆ†æ•£å¼ç³»çµ±: [MIT 6.824](https://pdos.csail.mit.edu/6.824/)

</details>

<details>
<summary><strong>Q: å­¸ç¿’ Spark éœ€è¦å¤šé•·æ™‚é–“ï¼Ÿ</strong></summary>

**æ ¹æ“šå€‹äººåŸºç¤ï¼š**
- **åŸºç¤ç¯‡** (ç¬¬1-3ç« ): 2-3 é€±
- **é€²éšç¯‡** (ç¬¬4-6ç« ): 3-4 é€±  
- **å¯¦æˆ°ç¯‡** (ç¬¬7-8ç« ): 2-3 é€±
- **ç¸½è¨ˆ**: 7-10 é€±çš„æŒçºŒå­¸ç¿’

**å­¸ç¿’å»ºè­°ï¼š**
- æ¯å¤©æŠ•å…¥ 1-2 å°æ™‚
- ç†è«–å­¸ç¿’ + å‹•æ‰‹å¯¦ä½œ
- åƒèˆ‡é–‹æºé …ç›®å¯¦è¸

</details>

<details>
<summary><strong>Q: æˆ‘æ‡‰è©²é¸æ“‡å“ªç¨®èªè¨€ï¼Ÿ</strong></summary>

**èªè¨€é¸æ“‡å»ºè­°ï¼š**
- **Python (PySpark)**: é©åˆæ•¸æ“šç§‘å­¸ã€æ©Ÿå™¨å­¸ç¿’ã€å¿«é€ŸåŸå‹é–‹ç™¼
- **Scala**: æ€§èƒ½æœ€ä½³ã€èˆ‡SparkåŸç”Ÿèªè¨€ç›¸åŒã€é©åˆå¤§è¦æ¨¡ç”Ÿç”¢
- **Java**: ä¼æ¥­ç´šé–‹ç™¼ã€åœ˜éšŠå”ä½œã€ç©©å®šå¯é 
- **R (SparkR)**: çµ±è¨ˆåˆ†æå°ˆæ¥­ã€å­¸è¡“ç ”ç©¶

**æœ¬èª²ç¨‹ä¸»è¦ä½¿ç”¨ Pythonï¼Œå› ç‚ºï¼š**
- å­¸ç¿’æ›²ç·šå¹³ç·©
- ç”Ÿæ…‹ç³»çµ±è±å¯Œ
- ç¤¾å€æ”¯æŒè‰¯å¥½
- èˆ‡æ•¸æ“šç§‘å­¸å·¥å…·æ•´åˆåº¦é«˜

</details>

<details>
<summary><strong>Q: å¦‚ä½•è™•ç†å®‰è£å•é¡Œï¼Ÿ</strong></summary>

**å¸¸è¦‹å•é¡Œè§£æ±ºï¼š**

1. **Java ç‰ˆæœ¬å•é¡Œ**:
   ```bash
   # æª¢æŸ¥Javaç‰ˆæœ¬
   java -version
   
   # å®‰è£OpenJDK 11 (æ¨è–¦)
   # macOS
   brew install openjdk@11
   
   # Ubuntu
   sudo apt install openjdk-11-jdk
   
   # è¨­ç½®JAVA_HOME
   export JAVA_HOME=$(/usr/libexec/java_home -v 11)
   ```

2. **Poetry å®‰è£å•é¡Œ**:
   ```bash
   # é‡æ–°å®‰è£Poetry
   curl -sSL https://install.python-poetry.org | python3 -
   
   # æ·»åŠ åˆ°PATH
   export PATH="$HOME/.local/bin:$PATH"
   ```

3. **ä¾è³´è¡çª**:
   ```bash
   # æ¸…ç†ä¸¦é‡æ–°å®‰è£
   poetry env remove --all
   poetry install
   ```

</details>

## ğŸ“š å­¸ç¿’è³‡æº

### å®˜æ–¹æ–‡æª”
- [Apache Spark å®˜æ–¹æ–‡æª”](https://spark.apache.org/docs/latest/)
- [PySpark API Reference](https://spark.apache.org/docs/latest/api/python/)
- [Spark SQL Guide](https://spark.apache.org/docs/latest/sql-programming-guide.html)

### æ¨è–¦æ›¸ç±
- ğŸ“– [Learning Spark, 2nd Edition](https://www.oreilly.com/library/view/learning-spark-2nd/9781492050032/)
- ğŸ“– [Spark: The Definitive Guide](https://www.oreilly.com/library/view/spark-the-definitive/9781491912201/)
- ğŸ“– [High Performance Spark](https://www.oreilly.com/library/view/high-performance-spark/9781491943199/)

### ç·šä¸Šèª²ç¨‹
- ğŸ“ [Databricks Academy](https://academy.databricks.com/)
- ğŸ“ [edX: Introduction to Apache Spark](https://www.edx.org/course/introduction-apache-spark-uc-berkeleyx-cs105x)
- ğŸ“ [Coursera: Big Data Specialization](https://www.coursera.org/specializations/big-data)

### ç¤¾ç¾¤è³‡æº
- ğŸ’¬ [Apache Spark ç”¨æˆ¶éƒµä»¶åˆ—è¡¨](https://spark.apache.org/community.html)
- ğŸ’¬ [Stack Overflow - Apache Spark](https://stackoverflow.com/questions/tagged/apache-spark)
- ğŸ’¬ [Reddit - r/apachespark](https://www.reddit.com/r/apachespark/)

## ğŸ¤ è²¢ç»æŒ‡å—

æˆ‘å€‘æ­¡è¿å„ç¨®å½¢å¼çš„è²¢ç»ï¼

### å¦‚ä½•è²¢ç»
1. **å ±å‘Šå•é¡Œ**: [æäº¤ Issue](https://github.com/myps6415/spark101/issues)
2. **æ”¹é€²æ–‡æª”**: ä¿®å¾©éŒ¯å­—ã€æ”¹å–„èªªæ˜
3. **æ–°å¢å…§å®¹**: æ·»åŠ æ–°çš„ç·´ç¿’æˆ–ç¯„ä¾‹
4. **å„ªåŒ–ä»£ç¢¼**: æå‡æ€§èƒ½å’Œå¯è®€æ€§
5. **åˆ†äº«ç¶“é©—**: æä¾›å­¸ç¿’å¿ƒå¾—å’Œæœ€ä½³å¯¦è¸

### è²¢ç»æµç¨‹
```bash
# 1. Fork å°ˆæ¡ˆ
git clone https://github.com/your-username/spark101.git

# 2. å‰µå»ºç‰¹æ€§åˆ†æ”¯
git checkout -b feature/your-feature-name

# 3. æäº¤æ›´æ”¹
git commit -m "Add: æè¿°ä½ çš„æ›´æ”¹"

# 4. æ¨é€åˆ†æ”¯
git push origin feature/your-feature-name

# 5. æäº¤ Pull Request
```

### è²¢ç»é¡å‹
- ğŸ› **Bug ä¿®å¾©**: ä¿®å¾©ä»£ç¢¼å•é¡Œ
- âœ¨ **æ–°åŠŸèƒ½**: æ·»åŠ æ–°çš„æ•™å­¸å…§å®¹
- ğŸ“š **æ–‡æª”æ”¹é€²**: å®Œå–„èªªæ˜å’Œæ•™ç¨‹
- ğŸ¨ **ä»£ç¢¼å„ªåŒ–**: æå‡ä»£ç¢¼å“è³ª
- ğŸ§ª **æ¸¬è©¦å¢å¼·**: å¢åŠ æ¸¬è©¦è¦†è“‹

## ğŸ“Š å°ˆæ¡ˆçµ±è¨ˆ

| é …ç›® | æ•¸é‡ | èªªæ˜ |
|------|------|------|
| ğŸ“š **æ•™å­¸ç« ç¯€** | 8ç«  | å¾åŸºç¤åˆ°é€²éšçš„å®Œæ•´å…§å®¹ |
| ğŸ“ **å¯¦ä½œç·´ç¿’** | 32å€‹ | æ¯ç« 4å€‹å¾ªåºæ¼¸é€²çš„ç·´ç¿’ |
| ğŸ““ **Jupyter Notebooks** | 8å€‹ | äº’å‹•å¼å­¸ç¿’é«”é©— |
| ğŸ—ï¸ **å¯¦æˆ°é …ç›®** | 3+1å€‹ | ä¼æ¥­ç´šæ‡‰ç”¨å ´æ™¯ |
| ğŸ§ª **æ¸¬è©¦æ–‡ä»¶** | 10å€‹ | å…¨é¢çš„å“è³ªä¿è­‰ |
| ğŸ“Š **æ•¸æ“šé›†** | 4å€‹ | çœŸå¯¦æ¥­å‹™å ´æ™¯æ•¸æ“š |
| ğŸ“– **ç¯„ä¾‹ç¨‹å¼** | 12å€‹ | æ ¸å¿ƒæ¦‚å¿µæ¼”ç¤º |
| ğŸ“„ **æ–‡æª”é é¢** | 100+ | è©³ç´°çš„å­¸ç¿’æŒ‡å— |

## ğŸ”„ æ›´æ–°æ—¥èªŒ

### v1.0.0 (2024-01-20)
- âœ¨ å®Œæ•´çš„8ç« æ•™å­¸å…§å®¹
- âœ¨ 32å€‹å¯¦ä½œç·´ç¿’
- âœ¨ 3å€‹ä¼æ¥­ç´šå¯¦æˆ°é …ç›®
- âœ¨ å®Œæ•´æ¸¬è©¦å¥—ä»¶
- âœ¨ è‡ªå‹•åŒ–ç’°å¢ƒè¨­ç½®
- âœ¨ è©³ç´°çš„ä¸­æ–‡æ–‡æª”

### è¨ˆåŠƒä¸­çš„åŠŸèƒ½
- ğŸš€ GitHub Actions CI/CD
- ğŸš€ Docker å®¹å™¨åŒ–éƒ¨ç½²
- ğŸš€ é›²ç«¯å¹³å°æ•´åˆ (AWS/Azure/GCP)
- ğŸš€ æ›´å¤šå¯¦æˆ°é …ç›®æ¡ˆä¾‹
- ğŸš€ è¦–é »æ•™å­¸å…§å®¹
- ğŸš€ å¤šèªè¨€æ”¯æŒ

## ğŸ“œ æˆæ¬Šå”è­°

æœ¬å°ˆæ¡ˆæ¡ç”¨ [MIT License](LICENSE) é–‹æºå”è­°ã€‚

```
MIT License

Copyright (c) 2024 JohnTung

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.
```

## ğŸ’ è‡´è¬

æ„Ÿè¬ä»¥ä¸‹è³‡æºå’Œé …ç›®çš„å•Ÿç™¼ï¼š
- [Apache Spark](https://spark.apache.org/) é–‹æºç¤¾ç¾¤
- [Databricks](https://databricks.com/) çš„å„ªç§€æ•™å­¸è³‡æº
- æ‰€æœ‰è²¢ç»è€…å’Œå­¸ç¿’è€…çš„å›é¥‹

## ğŸŒŸ æ”¯æŒå°ˆæ¡ˆ

å¦‚æœé€™å€‹å°ˆæ¡ˆå°ä½ æœ‰å¹«åŠ©ï¼Œè«‹è€ƒæ…®ï¼š

- â­ **çµ¦å°ˆæ¡ˆåŠ æ˜Ÿ**: åœ¨ GitHub ä¸Šé»æ“Š Star
- ğŸ”„ **åˆ†äº«å°ˆæ¡ˆ**: æ¨è–¦çµ¦æœ‹å‹å’ŒåŒäº‹
- ğŸ› **å›å ±å•é¡Œ**: å¹«åŠ©æˆ‘å€‘æ”¹é€²å°ˆæ¡ˆ
- ğŸ’¡ **æä¾›å»ºè­°**: åˆ†äº«ä½ çš„å­¸ç¿’ç¶“é©—
- ğŸ¤ **åƒèˆ‡è²¢ç»**: ä¸€èµ·å®Œå–„é€™å€‹å°ˆæ¡ˆ

---

<div align="center">

**ğŸ“ é–‹å§‹ä½ çš„ Apache Spark å­¸ç¿’ä¹‹æ—…ï¼**

[ğŸ“š æŸ¥çœ‹æ•™å­¸](./examples/) | [ğŸ’ª é–‹å§‹ç·´ç¿’](./exercises/) | [ğŸš€ å¯¦æˆ°é …ç›®](./projects/) | [ğŸ§ª é‹è¡Œæ¸¬è©¦](./tests/)

**Made with â¤ï¸ by [JohnTung](https://github.com/myps6415)**

â­ å¦‚æœé€™å€‹æ•™å­¸å°ä½ æœ‰å¹«åŠ©ï¼Œè«‹çµ¦å€‹ starï¼

</div>