# Spark 101 æ•™å­¸èª²ç¨‹

ğŸ”¥ å¾é›¶é–‹å§‹å­¸ç¿’ Apache Spark çš„å®Œæ•´æ•™å­¸è³‡æº

## ğŸ¯ å­¸ç¿’ç›®æ¨™

- æŒæ¡ Apache Spark çš„æ ¸å¿ƒæ¦‚å¿µå’Œæ¶æ§‹
- ç†Ÿç·´ä½¿ç”¨ Spark Core, DataFrame, SQL ç­‰ API
- å­¸æœƒ Spark Streaming å³æ™‚æ•¸æ“šè™•ç†
- äº†è§£ MLlib æ©Ÿå™¨å­¸ç¿’æ‡‰ç”¨
- æŒæ¡æ€§èƒ½èª¿å„ªæŠ€å·§
- å®Œæˆå¯¦æˆ°é …ç›®

## ğŸ“š èª²ç¨‹å¤§ç¶±

### åŸºç¤ç¯‡

#### ç¬¬1ç« ï¼šSpark åŸºç¤æ¦‚å¿µ
- ä»€éº¼æ˜¯ Apache Spark
- åˆ†æ•£å¼è¨ˆç®—æ¦‚å¿µ
- Spark vs Hadoop MapReduce
- å®‰è£å’Œç’°å¢ƒè¨­ç½®
- ç¬¬ä¸€å€‹ Spark ç¨‹å¼

#### ç¬¬2ç« ï¼šSpark Core åŸºæœ¬æ“ä½œ
- RDD (Resilient Distributed Dataset) æ¦‚å¿µ
- å‰µå»ºå’Œæ“ä½œ RDD
- Transformations vs Actions
- ä¸¦è¡ŒåŒ–å’Œåˆ†å€
- å®¹éŒ¯æ©Ÿåˆ¶

#### ç¬¬3ç« ï¼šDataFrame å’Œ Dataset API
- DataFrame åŸºæœ¬æ“ä½œ
- Schema å®šç¾©
- å¸¸ç”¨å‡½æ•¸å’Œæ“ä½œ
- è³‡æ–™è®€å¯«æ“ä½œ

### é€²éšç¯‡

#### ç¬¬4ç« ï¼šSpark SQL
- SQL æŸ¥è©¢èªæ³•
- è‡¨æ™‚è¦–åœ– (Temporary Views)
- å…§å»ºå‡½æ•¸
- è¤‡é›œæŸ¥è©¢æ“ä½œ
- æ€§èƒ½èª¿å„ª

#### ç¬¬5ç« ï¼šSpark Streaming
- æµå¼è™•ç†æ¦‚å¿µ
- DStream æ“ä½œ
- çµæ§‹åŒ–æµè™•ç† (Structured Streaming)
- å¯¦æ™‚æ•¸æ“šè™•ç†
- è¦–çª—æ“ä½œ

#### ç¬¬6ç« ï¼šMLlib æ©Ÿå™¨å­¸ç¿’
- æ©Ÿå™¨å­¸ç¿’åŸºç¤
- ç‰¹å¾µå·¥ç¨‹
- æ¨¡å‹è¨“ç·´å’Œè©•ä¼°
- ç®¡é“(Pipeline)
- å¸¸ç”¨æ¼”ç®—æ³•

### å¯¦æˆ°ç¯‡

#### ç¬¬7ç« ï¼šæ€§èƒ½èª¿å„ª
- è¨˜æ†¶é«”ç®¡ç†
- åŸ·è¡Œå™¨é…ç½®
- è³‡æ–™åºåˆ—åŒ–
- å¿«å–ç­–ç•¥
- åˆ†å€ç­–ç•¥

#### ç¬¬8ç« ï¼šå¯¦æˆ°é …ç›®
- æ—¥èªŒåˆ†æç³»çµ±
- æ¨è–¦ç³»çµ±
- å³æ™‚ç›£æ§ç³»çµ±
- å¤§æ•¸æ“š ETL

## ğŸ› ï¸ ç’°å¢ƒè¦æ±‚

- Java 8 æˆ–æ›´é«˜ç‰ˆæœ¬
- Python 3.6+ (å¦‚æœä½¿ç”¨ PySpark)
- Scala 2.12+ (å¦‚æœä½¿ç”¨ Scala)
- Apache Spark 3.0+
- è‡³å°‘ 4GB RAM

## ğŸ“¦ å®‰è£æŒ‡å—

### ä½¿ç”¨ Poetry (æ¨è–¦)

1. å®‰è£ Poetry
```bash
curl -sSL https://install.python-poetry.org | python3 -
```

2. å…‹éš†å°ˆæ¡ˆä¸¦å®‰è£ä¾è³´
```bash
git clone <your-repo-url>
cd spark101
poetry install
```

3. æ¿€æ´»è™›æ“¬ç’°å¢ƒ
```bash
poetry shell
```

4. åˆå§‹åŒ–ç’°å¢ƒï¼ˆå¯é¸ï¼‰
```bash
# ä½¿ç”¨ Makefileï¼ˆæ¨è–¦ï¼‰
make bootstrap

# æˆ–ç›´æ¥é‹è¡Œè…³æœ¬
python scripts/bootstrap.py
```

### å‚³çµ±å®‰è£æ–¹å¼

1. å®‰è£ Java
```bash
java -version
```

2. ä¸‹è¼‰ Spark
```bash
wget https://downloads.apache.org/spark/spark-3.5.0/spark-3.5.0-bin-hadoop3.tgz
tar -xzf spark-3.5.0-bin-hadoop3.tgz
```

3. è¨­å®šç’°å¢ƒè®Šæ•¸
```bash
export SPARK_HOME=/path/to/spark-3.5.0-bin-hadoop3
export PATH=$PATH:$SPARK_HOME/bin
```

4. å®‰è£ Python ä¾è³´
```bash
pip install pyspark jupyter pandas numpy matplotlib seaborn plotly
```

### ä½¿ç”¨ Docker

```bash
docker run -it --rm \
  -p 8888:8888 \
  jupyter/pyspark-notebook
```

## ğŸš€ å¿«é€Ÿé–‹å§‹

### ä½¿ç”¨ Poetry

1. é‹è¡Œç¬¬ä¸€å€‹ç¯„ä¾‹
```bash
# ä½¿ç”¨ Makefileï¼ˆæ¨è–¦ï¼‰
make run-examples

# æˆ–ç›´æ¥é‹è¡Œ
poetry run python examples/chapter01/hello_spark.py
```

2. å•Ÿå‹• Jupyter Notebook
```bash
# ä½¿ç”¨ Makefileï¼ˆæ¨è–¦ï¼‰
make jupyter

# æˆ–ç›´æ¥é‹è¡Œ
poetry run jupyter notebook
```

3. å•Ÿå‹• PySpark Shell
```bash
poetry run pyspark
```

### å¸¸ç”¨ Makefile å‘½ä»¤

```bash
make help         # é¡¯ç¤ºæ‰€æœ‰å¯ç”¨å‘½ä»¤
make install      # å®‰è£ä¾è³´
make dev          # è¨­ç½®é–‹ç™¼ç’°å¢ƒ
make bootstrap    # åˆå§‹åŒ–ç’°å¢ƒ
make test         # é‹è¡Œæ¸¬è©¦
make format       # æ ¼å¼åŒ–ä»£ç¢¼
make lint         # ä»£ç¢¼æª¢æŸ¥
make clean        # æ¸…ç†ç’°å¢ƒ
```

### å‚³çµ±æ–¹å¼

1. å•Ÿå‹• Spark Shell
```bash
spark-shell  # Scala
pyspark      # Python
```

2. ç¬¬ä¸€å€‹ç¨‹å¼
```python
# å‰µå»º SparkSession
from pyspark.sql import SparkSession
spark = SparkSession.builder.appName("Spark101").getOrCreate()

# å‰µå»º DataFrame
data = [("Alice", 25), ("Bob", 30), ("Charlie", 35)]
df = spark.createDataFrame(data, ["name", "age"])

# é¡¯ç¤ºçµæœ
df.show()
```

## ğŸ“‚ å°ˆæ¡ˆçµæ§‹

```
spark101/
â”œâ”€â”€ README.md
â”œâ”€â”€ pyproject.toml          # Poetry é…ç½®æ–‡ä»¶
â”œâ”€â”€ Makefile               # å°ˆæ¡ˆç®¡ç†å‘½ä»¤
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ bootstrap.py       # ç’°å¢ƒåˆå§‹åŒ–è…³æœ¬
â”œâ”€â”€ examples/
â”‚   â”œâ”€â”€ chapter01/
â”‚   â”œâ”€â”€ chapter02/
â”‚   â”œâ”€â”€ ...
â”‚   â””â”€â”€ chapter08/
â”œâ”€â”€ datasets/
â”‚   â”œâ”€â”€ sample_data.csv
â”‚   â””â”€â”€ ...
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_spark_basics.ipynb
â”‚   â””â”€â”€ ...
â””â”€â”€ projects/
    â”œâ”€â”€ log_analyzer/
    â”œâ”€â”€ recommendation_system/
    â””â”€â”€ ...
```

## ğŸ“ å­¸ç¿’å»ºè­°

1. **å¾ªåºæ¼¸é€²**ï¼šæŒ‰ç…§ç« ç¯€é †åºå­¸ç¿’
2. **å‹•æ‰‹å¯¦ä½œ**ï¼šæ¯å€‹æ¦‚å¿µéƒ½è¦è¦ªè‡ªå¯«ç¨‹å¼
3. **ç·´ç¿’ç‚ºä¸»**ï¼šç†è«–çµåˆå¯¦éš›æ“ä½œ
4. **æŸ¥çœ‹æ–‡æª”**ï¼šé¤ŠæˆæŸ¥é–±å®˜æ–¹æ–‡æª”çš„ç¿’æ…£
5. **åšç­†è¨˜**ï¼šè¨˜éŒ„é‡è¦æ¦‚å¿µå’Œè¸©éçš„å‘

## ğŸ“š åƒè€ƒè³‡æº

- [Apache Spark å®˜æ–¹æ–‡æª”](https://spark.apache.org/docs/latest/)
- [Spark Programming Guide](https://spark.apache.org/docs/latest/programming-guide.html)
- [PySpark API Reference](https://spark.apache.org/docs/latest/api/python/)
- [Scala API Reference](https://spark.apache.org/docs/latest/api/scala/)

## ğŸ’¡ å¸¸è¦‹å•é¡Œ

### Q: æˆ‘éœ€è¦ä»€éº¼åŸºç¤çŸ¥è­˜ï¼Ÿ
A: å»ºè­°å…·å‚™ï¼š
- åŸºæœ¬ç¨‹å¼è¨­è¨ˆèƒ½åŠ› (Python/Scala/Java)
- è³‡æ–™åº«å’Œ SQL åŸºç¤
- å°åˆ†æ•£å¼ç³»çµ±æœ‰åŸºæœ¬äº†è§£

### Q: å­¸ç¿’ Spark éœ€è¦å¤šé•·æ™‚é–“ï¼Ÿ
A: æ ¹æ“šå€‹äººåŸºç¤ï¼š
- åŸºç¤ç¯‡ï¼š2-3 é€±
- é€²éšç¯‡ï¼š3-4 é€±
- å¯¦æˆ°ç¯‡ï¼š2-3 é€±

### Q: æˆ‘æ‡‰è©²é¸æ“‡å“ªç¨®èªè¨€ï¼Ÿ
A: å»ºè­°ï¼š
- **Python**: é©åˆæ•¸æ“šç§‘å­¸å’Œæ©Ÿå™¨å­¸ç¿’
- **Scala**: æ€§èƒ½æœ€å¥½ï¼Œèˆ‡ Spark åŸç”Ÿèªè¨€ç›¸åŒ
- **Java**: ä¼æ¥­ç´šé–‹ç™¼

## ğŸ¤ è²¢ç»

æ­¡è¿æäº¤ Issue å’Œ Pull Requestï¼

## ğŸ“„ æˆæ¬Š

MIT License

---

â­ å¦‚æœé€™å€‹æ•™å­¸å°ä½ æœ‰å¹«åŠ©ï¼Œè«‹çµ¦å€‹ starï¼