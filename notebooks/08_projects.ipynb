{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第八章：實戰專案\n",
    "\n",
    "本章將通過三個完整的實戰專案來綜合應用前面學到的 Spark 技術。每個專案都模擬真實的業務場景，包含完整的資料處理流程。\n",
    "\n",
    "## 專案概覽\n",
    "1. **日誌分析系統** - 分析網站訪問日誌，識別異常行為\n",
    "2. **即時監控系統** - 監控系統指標，即時告警\n",
    "3. **推薦系統** - 基於協同過濾的商品推薦\n",
    "\n",
    "## 學習目標\n",
    "- 掌握端到端的 Spark 專案開發流程\n",
    "- 學習如何處理真實的業務問題\n",
    "- 了解 Spark 在不同領域的應用\n",
    "- 培養系統性思維和解決問題的能力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 導入必要的庫\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "# 建立 SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Spark Real-world Projects\") \\\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
    "    .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\") \\\n",
    "    .config(\"spark.sql.adaptive.skewJoin.enabled\", \"true\") \\\n",
    "    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "\n",
    "print(f\"Spark 版本: {spark.version}\")\n",
    "print(f\"可用核心數: {spark.sparkContext.defaultParallelism}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 專案一：日誌分析系統\n",
    "\n",
    "### 專案背景\n",
    "網站每天產生大量訪問日誌，需要分析這些日誌來：\n",
    "- 識別異常訪問模式\n",
    "- 分析用戶行為\n",
    "- 監控系統性能\n",
    "- 檢測潛在的安全威脅\n",
    "\n",
    "### 技術要點\n",
    "- 日誌解析和資料清理\n",
    "- 時間序列分析\n",
    "- 異常檢測\n",
    "- 資料視覺化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 專案一：日誌分析系統\n",
    "\n",
    "class LogAnalyzer:\n",
    "    def __init__(self, spark):\n",
    "        self.spark = spark\n",
    "        self.log_df = None\n",
    "        \n",
    "    def generate_sample_logs(self, num_logs=100000):\n",
    "        \"\"\"\n",
    "        生成模擬的網站訪問日誌\n",
    "        \"\"\"\n",
    "        print(f\"生成 {num_logs} 條模擬日誌...\")\n",
    "        \n",
    "        # 定義常見的 IP 地址、用戶代理、請求路徑等\n",
    "        ips = [f\"192.168.1.{i}\" for i in range(1, 100)] + \\\n",
    "              [f\"10.0.0.{i}\" for i in range(1, 50)] + \\\n",
    "              [\"suspicious.ip.1\", \"suspicious.ip.2\", \"suspicious.ip.3\"]  # 模擬異常 IP\n",
    "        \n",
    "        user_agents = [\n",
    "            \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36\",\n",
    "            \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36\",\n",
    "            \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36\",\n",
    "            \"bot/crawler\",  # 模擬爬蟲\n",
    "            \"malicious-bot\"  # 模擬惡意爬蟲\n",
    "        ]\n",
    "        \n",
    "        paths = [\n",
    "            \"/\", \"/home\", \"/about\", \"/contact\", \"/products\", \"/login\", \"/register\",\n",
    "            \"/api/users\", \"/api/products\", \"/api/orders\",\n",
    "            \"/admin\", \"/admin/users\", \"/admin/config\",  # 敏感路徑\n",
    "            \"/../../etc/passwd\", \"/admin/../../etc/passwd\"  # 模擬攻擊\n",
    "        ]\n",
    "        \n",
    "        methods = [\"GET\", \"POST\", \"PUT\", \"DELETE\", \"OPTIONS\"]\n",
    "        status_codes = [200, 201, 301, 302, 400, 401, 403, 404, 500, 502, 503]\n",
    "        \n",
    "        logs = []\n",
    "        base_time = datetime.now() - timedelta(days=7)\n",
    "        \n",
    "        for i in range(num_logs):\n",
    "            # 生成時間戳（模擬一週的日誌）\n",
    "            timestamp = base_time + timedelta(\n",
    "                days=random.randint(0, 6),\n",
    "                hours=random.randint(0, 23),\n",
    "                minutes=random.randint(0, 59),\n",
    "                seconds=random.randint(0, 59)\n",
    "            )\n",
    "            \n",
    "            # 模擬異常行為\n",
    "            if random.random() < 0.05:  # 5% 的請求是異常的\n",
    "                ip = random.choice([\"suspicious.ip.1\", \"suspicious.ip.2\", \"suspicious.ip.3\"])\n",
    "                path = random.choice([\"/admin\", \"/../../etc/passwd\", \"/admin/../../etc/passwd\"])\n",
    "                status_code = random.choice([401, 403, 404])\n",
    "                user_agent = random.choice([\"bot/crawler\", \"malicious-bot\"])\n",
    "                response_size = random.randint(100, 500)\n",
    "                response_time = random.uniform(0.1, 2.0)\n",
    "            else:\n",
    "                ip = random.choice(ips)\n",
    "                path = random.choice(paths)\n",
    "                status_code = random.choice(status_codes)\n",
    "                user_agent = random.choice(user_agents)\n",
    "                response_size = random.randint(500, 10000)\n",
    "                response_time = random.uniform(0.05, 1.0)\n",
    "            \n",
    "            method = random.choice(methods)\n",
    "            \n",
    "            # 生成日誌行（Apache Common Log Format）\n",
    "            log_line = f'{ip} - - [{timestamp.strftime(\"%d/%b/%Y:%H:%M:%S +0000\")}] \"{method} {path} HTTP/1.1\" {status_code} {response_size} \"{user_agent}\" {response_time:.3f}'\n",
    "            \n",
    "            logs.append((\n",
    "                timestamp,\n",
    "                ip,\n",
    "                method,\n",
    "                path,\n",
    "                status_code,\n",
    "                response_size,\n",
    "                user_agent,\n",
    "                response_time,\n",
    "                log_line\n",
    "            ))\n",
    "        \n",
    "        # 建立 DataFrame\n",
    "        schema = StructType([\n",
    "            StructField(\"timestamp\", TimestampType(), True),\n",
    "            StructField(\"ip\", StringType(), True),\n",
    "            StructField(\"method\", StringType(), True),\n",
    "            StructField(\"path\", StringType(), True),\n",
    "            StructField(\"status_code\", IntegerType(), True),\n",
    "            StructField(\"response_size\", IntegerType(), True),\n",
    "            StructField(\"user_agent\", StringType(), True),\n",
    "            StructField(\"response_time\", DoubleType(), True),\n",
    "            StructField(\"raw_log\", StringType(), True)\n",
    "        ])\n",
    "        \n",
    "        self.log_df = self.spark.createDataFrame(logs, schema)\n",
    "        print(f\"成功生成 {self.log_df.count()} 條日誌記錄\")\n",
    "        \n",
    "        return self.log_df\n",
    "    \n",
    "    def basic_statistics(self):\n",
    "        \"\"\"\n",
    "        基本統計分析\n",
    "        \"\"\"\n",
    "        print(\"\\n=== 基本統計分析 ===\")\n",
    "        \n",
    "        # 總體統計\n",
    "        total_requests = self.log_df.count()\n",
    "        unique_ips = self.log_df.select(\"ip\").distinct().count()\n",
    "        unique_paths = self.log_df.select(\"path\").distinct().count()\n",
    "        \n",
    "        print(f\"總請求數: {total_requests:,}\")\n",
    "        print(f\"唯一 IP 數: {unique_ips:,}\")\n",
    "        print(f\"唯一路徑數: {unique_paths:,}\")\n",
    "        \n",
    "        # 狀態碼分佈\n",
    "        print(\"\\n狀態碼分佈:\")\n",
    "        status_dist = self.log_df.groupBy(\"status_code\") \\\n",
    "                                .count() \\\n",
    "                                .orderBy(\"status_code\") \\\n",
    "                                .collect()\n",
    "        \n",
    "        for row in status_dist:\n",
    "            percentage = (row['count'] / total_requests) * 100\n",
    "            print(f\"  {row['status_code']}: {row['count']:,} ({percentage:.1f}%)\")\n",
    "        \n",
    "        # 請求方法分佈\n",
    "        print(\"\\n請求方法分佈:\")\n",
    "        method_dist = self.log_df.groupBy(\"method\") \\\n",
    "                                .count() \\\n",
    "                                .orderBy(col(\"count\").desc()) \\\n",
    "                                .collect()\n",
    "        \n",
    "        for row in method_dist:\n",
    "            percentage = (row['count'] / total_requests) * 100\n",
    "            print(f\"  {row['method']}: {row['count']:,} ({percentage:.1f}%)\")\n",
    "        \n",
    "        # 響應時間統計\n",
    "        print(\"\\n響應時間統計:\")\n",
    "        response_time_stats = self.log_df.select(\"response_time\").describe().collect()\n",
    "        for row in response_time_stats:\n",
    "            print(f\"  {row['summary']}: {float(row['response_time']):.3f}s\")\n",
    "    \n",
    "    def detect_anomalies(self):\n",
    "        \"\"\"\n",
    "        異常檢測\n",
    "        \"\"\"\n",
    "        print(\"\\n=== 異常檢測 ===\")\n",
    "        \n",
    "        # 1. 檢測高頻率請求的 IP（可能是攻擊或爬蟲）\n",
    "        print(\"\\n1. 高頻率請求 IP 檢測:\")\n",
    "        high_freq_ips = self.log_df.groupBy(\"ip\") \\\n",
    "                                  .count() \\\n",
    "                                  .filter(col(\"count\") > 1000) \\\n",
    "                                  .orderBy(col(\"count\").desc())\n",
    "        \n",
    "        high_freq_ips.show()\n",
    "        \n",
    "        # 2. 檢測異常狀態碼（4xx, 5xx 錯誤）\n",
    "        print(\"\\n2. 異常狀態碼分析:\")\n",
    "        error_analysis = self.log_df.filter((col(\"status_code\") >= 400) | (col(\"status_code\") >= 500)) \\\n",
    "                                   .groupBy(\"ip\", \"status_code\") \\\n",
    "                                   .count() \\\n",
    "                                   .filter(col(\"count\") > 50) \\\n",
    "                                   .orderBy(col(\"count\").desc())\n",
    "        \n",
    "        error_analysis.show()\n",
    "        \n",
    "        # 3. 檢測敏感路徑訪問\n",
    "        print(\"\\n3. 敏感路徑訪問檢測:\")\n",
    "        sensitive_paths = [\"/admin\", \"/../../etc/passwd\", \"/admin/../../etc/passwd\"]\n",
    "        \n",
    "        sensitive_access = self.log_df.filter(col(\"path\").rlike(\"admin|etc/passwd|config\")) \\\n",
    "                                     .groupBy(\"ip\", \"path\") \\\n",
    "                                     .count() \\\n",
    "                                     .orderBy(col(\"count\").desc())\n",
    "        \n",
    "        sensitive_access.show(truncate=False)\n",
    "        \n",
    "        # 4. 檢測異常響應時間\n",
    "        print(\"\\n4. 異常響應時間檢測:\")\n",
    "        \n",
    "        # 計算響應時間的統計量\n",
    "        response_time_stats = self.log_df.select(\n",
    "            mean(\"response_time\").alias(\"mean_response_time\"),\n",
    "            stddev(\"response_time\").alias(\"std_response_time\")\n",
    "        ).collect()[0]\n",
    "        \n",
    "        mean_time = response_time_stats['mean_response_time']\n",
    "        std_time = response_time_stats['std_response_time']\n",
    "        threshold = mean_time + 2 * std_time  # 2 標準差作為閾值\n",
    "        \n",
    "        slow_requests = self.log_df.filter(col(\"response_time\") > threshold) \\\n",
    "                                  .select(\"timestamp\", \"ip\", \"path\", \"response_time\") \\\n",
    "                                  .orderBy(col(\"response_time\").desc())\n",
    "        \n",
    "        print(f\"響應時間異常閾值: {threshold:.3f}s\")\n",
    "        print(f\"異常慢請求數量: {slow_requests.count()}\")\n",
    "        slow_requests.show(10)\n",
    "        \n",
    "        # 5. 檢測爬蟲行為\n",
    "        print(\"\\n5. 爬蟲行為檢測:\")\n",
    "        bot_behavior = self.log_df.filter(col(\"user_agent\").rlike(\"bot|crawler|spider\")) \\\n",
    "                                 .groupBy(\"ip\", \"user_agent\") \\\n",
    "                                 .count() \\\n",
    "                                 .orderBy(col(\"count\").desc())\n",
    "        \n",
    "        bot_behavior.show(truncate=False)\n",
    "        \n",
    "        return {\n",
    "            'high_freq_ips': high_freq_ips,\n",
    "            'error_analysis': error_analysis,\n",
    "            'sensitive_access': sensitive_access,\n",
    "            'slow_requests': slow_requests,\n",
    "            'bot_behavior': bot_behavior\n",
    "        }\n",
    "    \n",
    "    def time_series_analysis(self):\n",
    "        \"\"\"\n",
    "        時間序列分析\n",
    "        \"\"\"\n",
    "        print(\"\\n=== 時間序列分析 ===\")\n",
    "        \n",
    "        # 按小時統計請求量\n",
    "        hourly_stats = self.log_df.withColumn(\"hour\", hour(\"timestamp\")) \\\n",
    "                                 .groupBy(\"hour\") \\\n",
    "                                 .agg(\n",
    "                                     count(\"*\").alias(\"request_count\"),\n",
    "                                     avg(\"response_time\").alias(\"avg_response_time\"),\n",
    "                                     countDistinct(\"ip\").alias(\"unique_ips\")\n",
    "                                 ) \\\n",
    "                                 .orderBy(\"hour\")\n",
    "        \n",
    "        print(\"\\n每小時請求統計:\")\n",
    "        hourly_stats.show(24)\n",
    "        \n",
    "        # 按天統計\n",
    "        daily_stats = self.log_df.withColumn(\"date\", date_format(\"timestamp\", \"yyyy-MM-dd\")) \\\n",
    "                                .groupBy(\"date\") \\\n",
    "                                .agg(\n",
    "                                    count(\"*\").alias(\"request_count\"),\n",
    "                                    avg(\"response_time\").alias(\"avg_response_time\"),\n",
    "                                    countDistinct(\"ip\").alias(\"unique_ips\")\n",
    "                                ) \\\n",
    "                                .orderBy(\"date\")\n",
    "        \n",
    "        print(\"\\n每日請求統計:\")\n",
    "        daily_stats.show()\n",
    "        \n",
    "        # 視覺化時間序列\n",
    "        hourly_data = hourly_stats.toPandas()\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        \n",
    "        # 每小時請求量\n",
    "        axes[0, 0].plot(hourly_data['hour'], hourly_data['request_count'], marker='o')\n",
    "        axes[0, 0].set_title('每小時請求量')\n",
    "        axes[0, 0].set_xlabel('小時')\n",
    "        axes[0, 0].set_ylabel('請求數')\n",
    "        axes[0, 0].grid(True)\n",
    "        \n",
    "        # 每小時平均響應時間\n",
    "        axes[0, 1].plot(hourly_data['hour'], hourly_data['avg_response_time'], marker='o', color='red')\n",
    "        axes[0, 1].set_title('每小時平均響應時間')\n",
    "        axes[0, 1].set_xlabel('小時')\n",
    "        axes[0, 1].set_ylabel('響應時間 (秒)')\n",
    "        axes[0, 1].grid(True)\n",
    "        \n",
    "        # 每小時唯一 IP 數\n",
    "        axes[1, 0].plot(hourly_data['hour'], hourly_data['unique_ips'], marker='o', color='green')\n",
    "        axes[1, 0].set_title('每小時唯一 IP 數')\n",
    "        axes[1, 0].set_xlabel('小時')\n",
    "        axes[1, 0].set_ylabel('唯一 IP 數')\n",
    "        axes[1, 0].grid(True)\n",
    "        \n",
    "        # 狀態碼分佈\n",
    "        status_data = self.log_df.groupBy(\"status_code\").count().toPandas()\n",
    "        axes[1, 1].pie(status_data['count'], labels=status_data['status_code'], autopct='%1.1f%%')\n",
    "        axes[1, 1].set_title('狀態碼分佈')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return hourly_stats, daily_stats\n",
    "    \n",
    "    def generate_security_report(self):\n",
    "        \"\"\"\n",
    "        生成安全報告\n",
    "        \"\"\"\n",
    "        print(\"\\n=== 安全分析報告 ===\")\n",
    "        \n",
    "        # 威脅等級評估\n",
    "        threats = []\n",
    "        \n",
    "        # 檢測 SQL 注入嘗試\n",
    "        sql_injection = self.log_df.filter(\n",
    "            col(\"path\").rlike(\"(union|select|drop|insert|update|delete|script|alert)\") |\n",
    "            col(\"path\").contains(\"'\") |\n",
    "            col(\"path\").contains(\"--\")\n",
    "        ).count()\n",
    "        \n",
    "        if sql_injection > 0:\n",
    "            threats.append(f\"檢測到 {sql_injection} 次可能的 SQL 注入嘗試\")\n",
    "        \n",
    "        # 檢測目錄遍歷攻擊\n",
    "        directory_traversal = self.log_df.filter(\n",
    "            col(\"path\").contains(\"../\") |\n",
    "            col(\"path\").contains(\"..\\\\\")\n",
    "        ).count()\n",
    "        \n",
    "        if directory_traversal > 0:\n",
    "            threats.append(f\"檢測到 {directory_traversal} 次可能的目錄遍歷攻擊\")\n",
    "        \n",
    "        # 檢測暴力破解\n",
    "        brute_force = self.log_df.filter(\n",
    "            (col(\"path\").contains(\"/login\") | col(\"path\").contains(\"/admin\")) &\n",
    "            (col(\"status_code\") == 401)\n",
    "        ).groupBy(\"ip\").count().filter(col(\"count\") > 10).count()\n",
    "        \n",
    "        if brute_force > 0:\n",
    "            threats.append(f\"檢測到 {brute_force} 個 IP 可能進行暴力破解攻擊\")\n",
    "        \n",
    "        # 檢測 DDoS 攻擊\n",
    "        ddos_threshold = 5000  # 每個 IP 超過 5000 次請求視為可疑\n",
    "        ddos_ips = self.log_df.groupBy(\"ip\").count().filter(col(\"count\") > ddos_threshold).count()\n",
    "        \n",
    "        if ddos_ips > 0:\n",
    "            threats.append(f\"檢測到 {ddos_ips} 個 IP 可能進行 DDoS 攻擊\")\n",
    "        \n",
    "        # 輸出威脅報告\n",
    "        if threats:\n",
    "            print(\"\\n🚨 檢測到以下安全威脅:\")\n",
    "            for i, threat in enumerate(threats, 1):\n",
    "                print(f\"  {i}. {threat}\")\n",
    "        else:\n",
    "            print(\"\\n✅ 未檢測到明顯的安全威脅\")\n",
    "        \n",
    "        # 生成建議\n",
    "        print(\"\\n💡 安全建議:\")\n",
    "        suggestions = [\n",
    "            \"定期監控異常 IP 地址的活動\",\n",
    "            \"對敏感端點實施訪問控制\",\n",
    "            \"設置速率限制以防止暴力破解\",\n",
    "            \"啟用 Web 應用防火牆 (WAF)\",\n",
    "            \"定期更新安全規則和簽名\",\n",
    "            \"建立即時警報系統\"\n",
    "        ]\n",
    "        \n",
    "        for i, suggestion in enumerate(suggestions, 1):\n",
    "            print(f\"  {i}. {suggestion}\")\n",
    "        \n",
    "        return threats\n",
    "\n",
    "# 執行日誌分析系統\n",
    "print(\"=== 專案一：日誌分析系統 ===\")\n",
    "\n",
    "log_analyzer = LogAnalyzer(spark)\n",
    "log_data = log_analyzer.generate_sample_logs(50000)\n",
    "\n",
    "# 顯示樣本資料\n",
    "print(\"\\n日誌樣本:\")\n",
    "log_data.show(10, truncate=False)\n",
    "\n",
    "# 執行分析\n",
    "log_analyzer.basic_statistics()\n",
    "anomalies = log_analyzer.detect_anomalies()\n",
    "hourly_stats, daily_stats = log_analyzer.time_series_analysis()\n",
    "threats = log_analyzer.generate_security_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 專案二：即時監控系統\n",
    "\n",
    "### 專案背景\n",
    "建立一個即時監控系統來監控服務器和應用程式的健康狀態：\n",
    "- 監控系統指標（CPU、記憶體、磁碟、網路）\n",
    "- 檢測異常情況並發送警報\n",
    "- 提供歷史趨勢分析\n",
    "- 預測潛在的系統問題\n",
    "\n",
    "### 技術要點\n",
    "- 即時資料處理\n",
    "- 閾值監控\n",
    "- 趨勢分析\n",
    "- 異常預測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 專案二：即時監控系統\n",
    "\n",
    "class MonitoringSystem:\n",
    "    def __init__(self, spark):\n",
    "        self.spark = spark\n",
    "        self.metrics_df = None\n",
    "        self.alert_thresholds = {\n",
    "            'cpu_usage': 80.0,\n",
    "            'memory_usage': 85.0,\n",
    "            'disk_usage': 90.0,\n",
    "            'network_latency': 100.0,\n",
    "            'error_rate': 5.0\n",
    "        }\n",
    "    \n",
    "    def generate_metrics_data(self, num_records=50000):\n",
    "        \"\"\"\n",
    "        生成模擬的系統指標資料\n",
    "        \"\"\"\n",
    "        print(f\"生成 {num_records} 條系統指標資料...\")\n",
    "        \n",
    "        servers = [f\"server-{i:02d}\" for i in range(1, 21)]  # 20 台服務器\n",
    "        services = [\"web\", \"api\", \"database\", \"cache\", \"queue\"]\n",
    "        \n",
    "        metrics = []\n",
    "        base_time = datetime.now() - timedelta(hours=24)\n",
    "        \n",
    "        for i in range(num_records):\n",
    "            timestamp = base_time + timedelta(seconds=i * 30)  # 每 30 秒一個資料點\n",
    "            server = random.choice(servers)\n",
    "            service = random.choice(services)\n",
    "            \n",
    "            # 生成基準值\n",
    "            if service == \"database\":\n",
    "                # 資料庫通常使用更多 CPU 和記憶體\n",
    "                cpu_base = 60 + random.gauss(0, 10)\n",
    "                memory_base = 70 + random.gauss(0, 10)\n",
    "            elif service == \"web\":\n",
    "                cpu_base = 30 + random.gauss(0, 10)\n",
    "                memory_base = 40 + random.gauss(0, 10)\n",
    "            else:\n",
    "                cpu_base = 45 + random.gauss(0, 10)\n",
    "                memory_base = 50 + random.gauss(0, 10)\n",
    "            \n",
    "            # 模擬異常情況\n",
    "            if random.random() < 0.1:  # 10% 的時間有異常\n",
    "                cpu_usage = min(100, max(0, cpu_base + random.gauss(30, 10)))\n",
    "                memory_usage = min(100, max(0, memory_base + random.gauss(25, 10)))\n",
    "                disk_usage = min(100, max(0, random.gauss(85, 10)))\n",
    "                network_latency = max(0, random.gauss(120, 30))\n",
    "                error_rate = max(0, random.gauss(8, 3))\n",
    "            else:\n",
    "                cpu_usage = min(100, max(0, cpu_base))\n",
    "                memory_usage = min(100, max(0, memory_base))\n",
    "                disk_usage = min(100, max(0, random.gauss(65, 15)))\n",
    "                network_latency = max(0, random.gauss(25, 10))\n",
    "                error_rate = max(0, random.gauss(1, 0.5))\n",
    "            \n",
    "            request_count = max(0, int(random.gauss(100, 30)))\n",
    "            response_time = max(0, random.gauss(200, 50))\n",
    "            \n",
    "            metrics.append((\n",
    "                timestamp,\n",
    "                server,\n",
    "                service,\n",
    "                cpu_usage,\n",
    "                memory_usage,\n",
    "                disk_usage,\n",
    "                network_latency,\n",
    "                error_rate,\n",
    "                request_count,\n",
    "                response_time\n",
    "            ))\n",
    "        \n",
    "        schema = StructType([\n",
    "            StructField(\"timestamp\", TimestampType(), True),\n",
    "            StructField(\"server\", StringType(), True),\n",
    "            StructField(\"service\", StringType(), True),\n",
    "            StructField(\"cpu_usage\", DoubleType(), True),\n",
    "            StructField(\"memory_usage\", DoubleType(), True),\n",
    "            StructField(\"disk_usage\", DoubleType(), True),\n",
    "            StructField(\"network_latency\", DoubleType(), True),\n",
    "            StructField(\"error_rate\", DoubleType(), True),\n",
    "            StructField(\"request_count\", IntegerType(), True),\n",
    "            StructField(\"response_time\", DoubleType(), True)\n",
    "        ])\n",
    "        \n",
    "        self.metrics_df = self.spark.createDataFrame(metrics, schema)\n",
    "        print(f\"成功生成 {self.metrics_df.count()} 條系統指標\")\n",
    "        \n",
    "        return self.metrics_df\n",
    "    \n",
    "    def monitor_alerts(self):\n",
    "        \"\"\"\n",
    "        監控警報\n",
    "        \"\"\"\n",
    "        print(\"\\n=== 警報監控 ===\")\n",
    "        \n",
    "        alerts = []\n",
    "        \n",
    "        # CPU 使用率警報\n",
    "        cpu_alerts = self.metrics_df.filter(\n",
    "            col(\"cpu_usage\") > self.alert_thresholds['cpu_usage']\n",
    "        ).select(\"timestamp\", \"server\", \"service\", \"cpu_usage\")\n",
    "        \n",
    "        cpu_count = cpu_alerts.count()\n",
    "        if cpu_count > 0:\n",
    "            alerts.append(f\"CPU 使用率警報: {cpu_count} 次\")\n",
    "            print(f\"\\n🚨 CPU 使用率超過 {self.alert_thresholds['cpu_usage']}% 的記錄:\")\n",
    "            cpu_alerts.orderBy(col(\"cpu_usage\").desc()).show(10)\n",
    "        \n",
    "        # 記憶體使用率警報\n",
    "        memory_alerts = self.metrics_df.filter(\n",
    "            col(\"memory_usage\") > self.alert_thresholds['memory_usage']\n",
    "        ).select(\"timestamp\", \"server\", \"service\", \"memory_usage\")\n",
    "        \n",
    "        memory_count = memory_alerts.count()\n",
    "        if memory_count > 0:\n",
    "            alerts.append(f\"記憶體使用率警報: {memory_count} 次\")\n",
    "            print(f\"\\n🚨 記憶體使用率超過 {self.alert_thresholds['memory_usage']}% 的記錄:\")\n",
    "            memory_alerts.orderBy(col(\"memory_usage\").desc()).show(10)\n",
    "        \n",
    "        # 磁碟使用率警報\n",
    "        disk_alerts = self.metrics_df.filter(\n",
    "            col(\"disk_usage\") > self.alert_thresholds['disk_usage']\n",
    "        ).select(\"timestamp\", \"server\", \"service\", \"disk_usage\")\n",
    "        \n",
    "        disk_count = disk_alerts.count()\n",
    "        if disk_count > 0:\n",
    "            alerts.append(f\"磁碟使用率警報: {disk_count} 次\")\n",
    "            print(f\"\\n🚨 磁碟使用率超過 {self.alert_thresholds['disk_usage']}% 的記錄:\")\n",
    "            disk_alerts.orderBy(col(\"disk_usage\").desc()).show(10)\n",
    "        \n",
    "        # 網路延遲警報\n",
    "        network_alerts = self.metrics_df.filter(\n",
    "            col(\"network_latency\") > self.alert_thresholds['network_latency']\n",
    "        ).select(\"timestamp\", \"server\", \"service\", \"network_latency\")\n",
    "        \n",
    "        network_count = network_alerts.count()\n",
    "        if network_count > 0:\n",
    "            alerts.append(f\"網路延遲警報: {network_count} 次\")\n",
    "            print(f\"\\n🚨 網路延遲超過 {self.alert_thresholds['network_latency']}ms 的記錄:\")\n",
    "            network_alerts.orderBy(col(\"network_latency\").desc()).show(10)\n",
    "        \n",
    "        # 錯誤率警報\n",
    "        error_alerts = self.metrics_df.filter(\n",
    "            col(\"error_rate\") > self.alert_thresholds['error_rate']\n",
    "        ).select(\"timestamp\", \"server\", \"service\", \"error_rate\")\n",
    "        \n",
    "        error_count = error_alerts.count()\n",
    "        if error_count > 0:\n",
    "            alerts.append(f\"錯誤率警報: {error_count} 次\")\n",
    "            print(f\"\\n🚨 錯誤率超過 {self.alert_thresholds['error_rate']}% 的記錄:\")\n",
    "            error_alerts.orderBy(col(\"error_rate\").desc()).show(10)\n",
    "        \n",
    "        # 生成警報摘要\n",
    "        print(\"\\n📊 警報摘要:\")\n",
    "        if alerts:\n",
    "            for alert in alerts:\n",
    "                print(f\"  • {alert}\")\n",
    "        else:\n",
    "            print(\"  ✅ 沒有觸發警報\")\n",
    "        \n",
    "        return alerts\n",
    "    \n",
    "    def system_health_dashboard(self):\n",
    "        \"\"\"\n",
    "        系統健康儀表板\n",
    "        \"\"\"\n",
    "        print(\"\\n=== 系統健康儀表板 ===\")\n",
    "        \n",
    "        # 計算各服務的平均指標\n",
    "        service_health = self.metrics_df.groupBy(\"service\").agg(\n",
    "            avg(\"cpu_usage\").alias(\"avg_cpu\"),\n",
    "            avg(\"memory_usage\").alias(\"avg_memory\"),\n",
    "            avg(\"disk_usage\").alias(\"avg_disk\"),\n",
    "            avg(\"network_latency\").alias(\"avg_latency\"),\n",
    "            avg(\"error_rate\").alias(\"avg_error_rate\"),\n",
    "            avg(\"response_time\").alias(\"avg_response_time\")\n",
    "        ).orderBy(\"service\")\n",
    "        \n",
    "        print(\"\\n各服務健康狀態:\")\n",
    "        service_health.show()\n",
    "        \n",
    "        # 計算各服務器的平均指標\n",
    "        server_health = self.metrics_df.groupBy(\"server\").agg(\n",
    "            avg(\"cpu_usage\").alias(\"avg_cpu\"),\n",
    "            avg(\"memory_usage\").alias(\"avg_memory\"),\n",
    "            avg(\"disk_usage\").alias(\"avg_disk\"),\n",
    "            count(\"*\").alias(\"data_points\")\n",
    "        ).orderBy(\"server\")\n",
    "        \n",
    "        print(\"\\n各服務器健康狀態:\")\n",
    "        server_health.show()\n",
    "        \n",
    "        # 識別最繁忙的服務器\n",
    "        busy_servers = self.metrics_df.groupBy(\"server\").agg(\n",
    "            avg(\"cpu_usage\").alias(\"avg_cpu\"),\n",
    "            avg(\"memory_usage\").alias(\"avg_memory\"),\n",
    "            sum(\"request_count\").alias(\"total_requests\")\n",
    "        ).orderBy(col(\"avg_cpu\").desc())\n",
    "        \n",
    "        print(\"\\n最繁忙的服務器 (按 CPU 使用率排序):\")\n",
    "        busy_servers.show(10)\n",
    "        \n",
    "        # 視覺化系統健康狀態\n",
    "        service_data = service_health.toPandas()\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "        \n",
    "        # CPU 使用率\n",
    "        axes[0, 0].bar(service_data['service'], service_data['avg_cpu'])\n",
    "        axes[0, 0].set_title('各服務平均 CPU 使用率')\n",
    "        axes[0, 0].set_ylabel('CPU 使用率 (%)')\n",
    "        axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # 記憶體使用率\n",
    "        axes[0, 1].bar(service_data['service'], service_data['avg_memory'], color='orange')\n",
    "        axes[0, 1].set_title('各服務平均記憶體使用率')\n",
    "        axes[0, 1].set_ylabel('記憶體使用率 (%)')\n",
    "        axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # 磁碟使用率\n",
    "        axes[0, 2].bar(service_data['service'], service_data['avg_disk'], color='green')\n",
    "        axes[0, 2].set_title('各服務平均磁碟使用率')\n",
    "        axes[0, 2].set_ylabel('磁碟使用率 (%)')\n",
    "        axes[0, 2].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # 網路延遲\n",
    "        axes[1, 0].bar(service_data['service'], service_data['avg_latency'], color='red')\n",
    "        axes[1, 0].set_title('各服務平均網路延遲')\n",
    "        axes[1, 0].set_ylabel('延遲 (ms)')\n",
    "        axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # 錯誤率\n",
    "        axes[1, 1].bar(service_data['service'], service_data['avg_error_rate'], color='purple')\n",
    "        axes[1, 1].set_title('各服務平均錯誤率')\n",
    "        axes[1, 1].set_ylabel('錯誤率 (%)')\n",
    "        axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # 響應時間\n",
    "        axes[1, 2].bar(service_data['service'], service_data['avg_response_time'], color='brown')\n",
    "        axes[1, 2].set_title('各服務平均響應時間')\n",
    "        axes[1, 2].set_ylabel('響應時間 (ms)')\n",
    "        axes[1, 2].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return service_health, server_health\n",
    "    \n",
    "    def trend_analysis(self):\n",
    "        \"\"\"\n",
    "        趨勢分析\n",
    "        \"\"\"\n",
    "        print(\"\\n=== 趨勢分析 ===\")\n",
    "        \n",
    "        # 按小時分析趨勢\n",
    "        hourly_trends = self.metrics_df.withColumn(\"hour\", hour(\"timestamp\")) \\\n",
    "                                      .groupBy(\"hour\") \\\n",
    "                                      .agg(\n",
    "                                          avg(\"cpu_usage\").alias(\"avg_cpu\"),\n",
    "                                          avg(\"memory_usage\").alias(\"avg_memory\"),\n",
    "                                          avg(\"network_latency\").alias(\"avg_latency\"),\n",
    "                                          sum(\"request_count\").alias(\"total_requests\")\n",
    "                                      ) \\\n",
    "                                      .orderBy(\"hour\")\n",
    "        \n",
    "        print(\"\\n每小時趨勢:\")\n",
    "        hourly_trends.show(24)\n",
    "        \n",
    "        # 檢測異常趨勢\n",
    "        print(\"\\n異常趨勢檢測:\")\n",
    "        \n",
    "        # 計算移動平均\n",
    "        window_spec = Window.orderBy(\"timestamp\").rowsBetween(-4, 0)  # 5 點移動平均\n",
    "        \n",
    "        with_moving_avg = self.metrics_df.withColumn(\n",
    "            \"cpu_moving_avg\", avg(\"cpu_usage\").over(window_spec)\n",
    "        ).withColumn(\n",
    "            \"cpu_deviation\", abs(col(\"cpu_usage\") - col(\"cpu_moving_avg\"))\n",
    "        )\n",
    "        \n",
    "        # 找出偏離移動平均較大的點\n",
    "        anomalies = with_moving_avg.filter(col(\"cpu_deviation\") > 20) \\\n",
    "                                  .select(\"timestamp\", \"server\", \"service\", \"cpu_usage\", \"cpu_moving_avg\", \"cpu_deviation\") \\\n",
    "                                  .orderBy(col(\"cpu_deviation\").desc())\n",
    "        \n",
    "        print(f\"檢測到 {anomalies.count()} 個 CPU 使用率異常點:\")\n",
    "        anomalies.show(10)\n",
    "        \n",
    "        # 視覺化趨勢\n",
    "        trend_data = hourly_trends.toPandas()\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        \n",
    "        # CPU 趨勢\n",
    "        axes[0, 0].plot(trend_data['hour'], trend_data['avg_cpu'], marker='o')\n",
    "        axes[0, 0].set_title('每小時平均 CPU 使用率趨勢')\n",
    "        axes[0, 0].set_xlabel('小時')\n",
    "        axes[0, 0].set_ylabel('CPU 使用率 (%)')\n",
    "        axes[0, 0].grid(True)\n",
    "        \n",
    "        # 記憶體趨勢\n",
    "        axes[0, 1].plot(trend_data['hour'], trend_data['avg_memory'], marker='o', color='orange')\n",
    "        axes[0, 1].set_title('每小時平均記憶體使用率趨勢')\n",
    "        axes[0, 1].set_xlabel('小時')\n",
    "        axes[0, 1].set_ylabel('記憶體使用率 (%)')\n",
    "        axes[0, 1].grid(True)\n",
    "        \n",
    "        # 網路延遲趨勢\n",
    "        axes[1, 0].plot(trend_data['hour'], trend_data['avg_latency'], marker='o', color='red')\n",
    "        axes[1, 0].set_title('每小時平均網路延遲趨勢')\n",
    "        axes[1, 0].set_xlabel('小時')\n",
    "        axes[1, 0].set_ylabel('延遲 (ms)')\n",
    "        axes[1, 0].grid(True)\n",
    "        \n",
    "        # 請求量趨勢\n",
    "        axes[1, 1].plot(trend_data['hour'], trend_data['total_requests'], marker='o', color='green')\n",
    "        axes[1, 1].set_title('每小時總請求量趨勢')\n",
    "        axes[1, 1].set_xlabel('小時')\n",
    "        axes[1, 1].set_ylabel('請求數')\n",
    "        axes[1, 1].grid(True)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return hourly_trends, anomalies\n",
    "    \n",
    "    def generate_monitoring_report(self):\n",
    "        \"\"\"\n",
    "        生成監控報告\n",
    "        \"\"\"\n",
    "        print(\"\\n=== 監控報告 ===\")\n",
    "        \n",
    "        # 系統整體健康度評分\n",
    "        avg_metrics = self.metrics_df.agg(\n",
    "            avg(\"cpu_usage\").alias(\"avg_cpu\"),\n",
    "            avg(\"memory_usage\").alias(\"avg_memory\"),\n",
    "            avg(\"disk_usage\").alias(\"avg_disk\"),\n",
    "            avg(\"network_latency\").alias(\"avg_latency\"),\n",
    "            avg(\"error_rate\").alias(\"avg_error_rate\")\n",
    "        ).collect()[0]\n",
    "        \n",
    "        # 計算健康度評分（0-100）\n",
    "        cpu_score = max(0, 100 - avg_metrics['avg_cpu'])\n",
    "        memory_score = max(0, 100 - avg_metrics['avg_memory'])\n",
    "        disk_score = max(0, 100 - avg_metrics['avg_disk'])\n",
    "        latency_score = max(0, 100 - avg_metrics['avg_latency'])\n",
    "        error_score = max(0, 100 - avg_metrics['avg_error_rate'] * 10)\n",
    "        \n",
    "        overall_score = (cpu_score + memory_score + disk_score + latency_score + error_score) / 5\n",
    "        \n",
    "        print(f\"\\n🏥 系統整體健康度評分: {overall_score:.1f}/100\")\n",
    "        \n",
    "        # 健康度等級\n",
    "        if overall_score >= 80:\n",
    "            health_status = \"優秀 😊\"\n",
    "        elif overall_score >= 60:\n",
    "            health_status = \"良好 🙂\"\n",
    "        elif overall_score >= 40:\n",
    "            health_status = \"一般 😐\"\n",
    "        else:\n",
    "            health_status = \"需要關注 😰\"\n",
    "        \n",
    "        print(f\"健康度等級: {health_status}\")\n",
    "        \n",
    "        # 詳細指標\n",
    "        print(\"\\n📊 詳細指標:\")\n",
    "        print(f\"  CPU 使用率: {avg_metrics['avg_cpu']:.1f}% (評分: {cpu_score:.1f})\")\n",
    "        print(f\"  記憶體使用率: {avg_metrics['avg_memory']:.1f}% (評分: {memory_score:.1f})\")\n",
    "        print(f\"  磁碟使用率: {avg_metrics['avg_disk']:.1f}% (評分: {disk_score:.1f})\")\n",
    "        print(f\"  網路延遲: {avg_metrics['avg_latency']:.1f}ms (評分: {latency_score:.1f})\")\n",
    "        print(f\"  錯誤率: {avg_metrics['avg_error_rate']:.1f}% (評分: {error_score:.1f})\")\n",
    "        \n",
    "        # 建議\n",
    "        print(\"\\n💡 優化建議:\")\n",
    "        recommendations = []\n",
    "        \n",
    "        if avg_metrics['avg_cpu'] > 70:\n",
    "            recommendations.append(\"CPU 使用率偏高，建議優化程式碼或增加服務器資源\")\n",
    "        \n",
    "        if avg_metrics['avg_memory'] > 80:\n",
    "            recommendations.append(\"記憶體使用率偏高，建議檢查記憶體洩漏或增加記憶體\")\n",
    "        \n",
    "        if avg_metrics['avg_disk'] > 85:\n",
    "            recommendations.append(\"磁碟使用率偏高，建議清理或擴展磁碟空間\")\n",
    "        \n",
    "        if avg_metrics['avg_latency'] > 50:\n",
    "            recommendations.append(\"網路延遲較高，建議檢查網路配置或優化網路拓撲\")\n",
    "        \n",
    "        if avg_metrics['avg_error_rate'] > 3:\n",
    "            recommendations.append(\"錯誤率偏高，建議檢查應用程式日誌和錯誤處理\")\n",
    "        \n",
    "        if recommendations:\n",
    "            for i, rec in enumerate(recommendations, 1):\n",
    "                print(f\"  {i}. {rec}\")\n",
    "        else:\n",
    "            print(\"  ✅ 系統運行良好，暫無特別建議\")\n",
    "        \n",
    "        return {\n",
    "            'overall_score': overall_score,\n",
    "            'health_status': health_status,\n",
    "            'avg_metrics': avg_metrics,\n",
    "            'recommendations': recommendations\n",
    "        }\n",
    "\n",
    "# 執行監控系統\n",
    "print(\"\\n=== 專案二：即時監控系統 ===\")\n",
    "\n",
    "monitoring_system = MonitoringSystem(spark)\n",
    "metrics_data = monitoring_system.generate_metrics_data(20000)\n",
    "\n",
    "# 顯示樣本資料\n",
    "print(\"\\n系統指標樣本:\")\n",
    "metrics_data.show(10)\n",
    "\n",
    "# 執行監控分析\n",
    "alerts = monitoring_system.monitor_alerts()\n",
    "service_health, server_health = monitoring_system.system_health_dashboard()\n",
    "hourly_trends, anomalies = monitoring_system.trend_analysis()\n",
    "monitoring_report = monitoring_system.generate_monitoring_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 專案三：推薦系統\n",
    "\n",
    "### 專案背景\n",
    "建立一個基於協同過濾的商品推薦系統：\n",
    "- 分析用戶行為和購買歷史\n",
    "- 使用協同過濾演算法生成推薦\n",
    "- 評估推薦系統的性能\n",
    "- 提供個性化推薦結果\n",
    "\n",
    "### 技術要點\n",
    "- 協同過濾 (Collaborative Filtering)\n",
    "- 矩陣分解 (Matrix Factorization)\n",
    "- 推薦評估指標\n",
    "- 大規模推薦系統"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 專案三：推薦系統\n",
    "\n",
    "class RecommendationSystem:\n",
    "    def __init__(self, spark):\n",
    "        self.spark = spark\n",
    "        self.ratings_df = None\n",
    "        self.products_df = None\n",
    "        self.users_df = None\n",
    "        self.model = None\n",
    "    \n",
    "    def generate_sample_data(self, num_users=1000, num_products=500, num_ratings=50000):\n",
    "        \"\"\"\n",
    "        生成模擬的用戶評分資料\n",
    "        \"\"\"\n",
    "        print(f\"生成推薦系統資料: {num_users} 用戶, {num_products} 商品, {num_ratings} 評分...\")\n",
    "        \n",
    "        # 生成商品資料\n",
    "        categories = ['Electronics', 'Books', 'Clothing', 'Sports', 'Home', 'Beauty', 'Automotive']\n",
    "        products = []\n",
    "        \n",
    "        for i in range(num_products):\n",
    "            products.append((\n",
    "                i + 1,  # product_id\n",
    "                f\"Product {i+1}\",\n",
    "                random.choice(categories),\n",
    "                random.uniform(10, 500),  # price\n",
    "                random.uniform(3.0, 5.0)  # avg_rating\n",
    "            ))\n",
    "        \n",
    "        products_schema = StructType([\n",
    "            StructField(\"product_id\", IntegerType(), True),\n",
    "            StructField(\"product_name\", StringType(), True),\n",
    "            StructField(\"category\", StringType(), True),\n",
    "            StructField(\"price\", DoubleType(), True),\n",
    "            StructField(\"avg_rating\", DoubleType(), True)\n",
    "        ])\n",
    "        \n",
    "        self.products_df = self.spark.createDataFrame(products, products_schema)\n",
    "        \n",
    "        # 生成用戶資料\n",
    "        users = []\n",
    "        age_groups = ['18-25', '26-35', '36-45', '46-55', '56+']\n",
    "        genders = ['M', 'F']\n",
    "        \n",
    "        for i in range(num_users):\n",
    "            users.append((\n",
    "                i + 1,  # user_id\n",
    "                f\"User {i+1}\",\n",
    "                random.choice(age_groups),\n",
    "                random.choice(genders),\n",
    "                random.choice(categories)  # preferred_category\n",
    "            ))\n",
    "        \n",
    "        users_schema = StructType([\n",
    "            StructField(\"user_id\", IntegerType(), True),\n",
    "            StructField(\"user_name\", StringType(), True),\n",
    "            StructField(\"age_group\", StringType(), True),\n",
    "            StructField(\"gender\", StringType(), True),\n",
    "            StructField(\"preferred_category\", StringType(), True)\n",
    "        ])\n",
    "        \n",
    "        self.users_df = self.spark.createDataFrame(users, users_schema)\n",
    "        \n",
    "        # 生成評分資料\n",
    "        ratings = []\n",
    "        \n",
    "        for _ in range(num_ratings):\n",
    "            user_id = random.randint(1, num_users)\n",
    "            product_id = random.randint(1, num_products)\n",
    "            \n",
    "            # 模擬用戶偏好（用戶更可能對偏好類別的商品給高分）\n",
    "            user_preferred_category = users[user_id - 1][4]\n",
    "            product_category = products[product_id - 1][2]\n",
    "            \n",
    "            if user_preferred_category == product_category:\n",
    "                # 偏好類別，更高的評分\n",
    "                rating = random.choices([3, 4, 5], weights=[0.2, 0.4, 0.4])[0]\n",
    "            else:\n",
    "                # 非偏好類別，更分散的評分\n",
    "                rating = random.choices([1, 2, 3, 4, 5], weights=[0.1, 0.2, 0.4, 0.2, 0.1])[0]\n",
    "            \n",
    "            timestamp = datetime.now() - timedelta(days=random.randint(0, 365))\n",
    "            \n",
    "            ratings.append((\n",
    "                user_id,\n",
    "                product_id,\n",
    "                float(rating),\n",
    "                timestamp\n",
    "            ))\n",
    "        \n",
    "        ratings_schema = StructType([\n",
    "            StructField(\"user_id\", IntegerType(), True),\n",
    "            StructField(\"product_id\", IntegerType(), True),\n",
    "            StructField(\"rating\", FloatType(), True),\n",
    "            StructField(\"timestamp\", TimestampType(), True)\n",
    "        ])\n",
    "        \n",
    "        self.ratings_df = self.spark.createDataFrame(ratings, ratings_schema)\n",
    "        \n",
    "        print(f\"生成完成: {self.users_df.count()} 用戶, {self.products_df.count()} 商品, {self.ratings_df.count()} 評分\")\n",
    "        \n",
    "        return self.ratings_df, self.products_df, self.users_df\n",
    "    \n",
    "    def exploratory_analysis(self):\n",
    "        \"\"\"\n",
    "        探索性資料分析\n",
    "        \"\"\"\n",
    "        print(\"\\n=== 探索性資料分析 ===\")\n",
    "        \n",
    "        # 基本統計\n",
    "        total_ratings = self.ratings_df.count()\n",
    "        unique_users = self.ratings_df.select(\"user_id\").distinct().count()\n",
    "        unique_products = self.ratings_df.select(\"product_id\").distinct().count()\n",
    "        \n",
    "        print(f\"總評分數: {total_ratings:,}\")\n",
    "        print(f\"活躍用戶數: {unique_users:,}\")\n",
    "        print(f\"被評分商品數: {unique_products:,}\")\n",
    "        \n",
    "        # 評分分佈\n",
    "        print(\"\\n評分分佈:\")\n",
    "        rating_dist = self.ratings_df.groupBy(\"rating\").count().orderBy(\"rating\")\n",
    "        rating_dist.show()\n",
    "        \n",
    "        # 用戶活躍度分析\n",
    "        print(\"\\n用戶活躍度分析:\")\n",
    "        user_activity = self.ratings_df.groupBy(\"user_id\").count().alias(\"rating_count\")\n",
    "        user_activity_stats = user_activity.describe(\"count\")\n",
    "        user_activity_stats.show()\n",
    "        \n",
    "        # 商品受歡迎程度\n",
    "        print(\"\\n最受歡迎的商品:\")\n",
    "        popular_products = self.ratings_df.groupBy(\"product_id\").agg(\n",
    "            count(\"rating\").alias(\"rating_count\"),\n",
    "            avg(\"rating\").alias(\"avg_rating\")\n",
    "        ).join(self.products_df, \"product_id\") \\\n",
    "         .orderBy(col(\"rating_count\").desc())\n",
    "        \n",
    "        popular_products.select(\"product_name\", \"category\", \"rating_count\", \"avg_rating\").show(10)\n",
    "        \n",
    "        # 分類偏好分析\n",
    "        print(\"\\n分類偏好分析:\")\n",
    "        category_preference = self.ratings_df.join(self.products_df, \"product_id\") \\\n",
    "                                           .groupBy(\"category\").agg(\n",
    "                                               count(\"rating\").alias(\"rating_count\"),\n",
    "                                               avg(\"rating\").alias(\"avg_rating\")\n",
    "                                           ).orderBy(col(\"rating_count\").desc())\n",
    "        \n",
    "        category_preference.show()\n",
    "        \n",
    "        # 視覺化\n",
    "        rating_data = rating_dist.toPandas()\n",
    "        category_data = category_preference.toPandas()\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        \n",
    "        # 評分分佈\n",
    "        axes[0, 0].bar(rating_data['rating'], rating_data['count'])\n",
    "        axes[0, 0].set_title('評分分佈')\n",
    "        axes[0, 0].set_xlabel('評分')\n",
    "        axes[0, 0].set_ylabel('數量')\n",
    "        \n",
    "        # 分類評分數量\n",
    "        axes[0, 1].bar(category_data['category'], category_data['rating_count'])\n",
    "        axes[0, 1].set_title('各分類評分數量')\n",
    "        axes[0, 1].set_xlabel('分類')\n",
    "        axes[0, 1].set_ylabel('評分數量')\n",
    "        axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # 分類平均評分\n",
    "        axes[1, 0].bar(category_data['category'], category_data['avg_rating'], color='green')\n",
    "        axes[1, 0].set_title('各分類平均評分')\n",
    "        axes[1, 0].set_xlabel('分類')\n",
    "        axes[1, 0].set_ylabel('平均評分')\n",
    "        axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # 用戶活躍度分佈\n",
    "        user_activity_data = user_activity.toPandas()\n",
    "        axes[1, 1].hist(user_activity_data['count'], bins=20, alpha=0.7)\n",
    "        axes[1, 1].set_title('用戶活躍度分佈')\n",
    "        axes[1, 1].set_xlabel('評分數量')\n",
    "        axes[1, 1].set_ylabel('用戶數量')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return popular_products, category_preference\n",
    "    \n",
    "    def build_recommendation_model(self):\n",
    "        \"\"\"\n",
    "        建立推薦模型\n",
    "        \"\"\"\n",
    "        print(\"\\n=== 建立推薦模型 ===\")\n",
    "        \n",
    "        # 分割訓練和測試資料\n",
    "        train_df, test_df = self.ratings_df.randomSplit([0.8, 0.2], seed=42)\n",
    "        \n",
    "        print(f\"訓練資料: {train_df.count()} 筆\")\n",
    "        print(f\"測試資料: {test_df.count()} 筆\")\n",
    "        \n",
    "        # 使用 ALS (Alternating Least Squares) 建立模型\n",
    "        als = ALS(\n",
    "            userCol=\"user_id\",\n",
    "            itemCol=\"product_id\",\n",
    "            ratingCol=\"rating\",\n",
    "            rank=50,  # 潛在因子數量\n",
    "            maxIter=10,\n",
    "            regParam=0.01,\n",
    "            coldStartStrategy=\"drop\",\n",
    "            nonnegative=True\n",
    "        )\n",
    "        \n",
    "        print(\"\\n訓練 ALS 模型...\")\n",
    "        self.model = als.fit(train_df)\n",
    "        \n",
    "        # 在測試集上評估模型\n",
    "        predictions = self.model.transform(test_df)\n",
    "        \n",
    "        # 計算 RMSE\n",
    "        evaluator = RegressionEvaluator(\n",
    "            metricName=\"rmse\",\n",
    "            labelCol=\"rating\",\n",
    "            predictionCol=\"prediction\"\n",
    "        )\n",
    "        \n",
    "        rmse = evaluator.evaluate(predictions)\n",
    "        print(f\"\\n模型 RMSE: {rmse:.4f}\")\n",
    "        \n",
    "        # 顯示一些預測結果\n",
    "        print(\"\\n預測結果樣本:\")\n",
    "        predictions.select(\"user_id\", \"product_id\", \"rating\", \"prediction\").show(10)\n",
    "        \n",
    "        return self.model, rmse\n",
    "    \n",
    "    def generate_recommendations(self, user_id, num_recommendations=10):\n",
    "        \"\"\"\n",
    "        為特定用戶生成推薦\n",
    "        \"\"\"\n",
    "        print(f\"\\n=== 為用戶 {user_id} 生成推薦 ===\")\n",
    "        \n",
    "        # 獲取用戶已評分的商品\n",
    "        user_ratings = self.ratings_df.filter(col(\"user_id\") == user_id)\n",
    "        rated_products = user_ratings.select(\"product_id\").rdd.map(lambda x: x[0]).collect()\n",
    "        \n",
    "        print(f\"用戶 {user_id} 已評分商品數: {len(rated_products)}\")\n",
    "        \n",
    "        # 顯示用戶的評分歷史\n",
    "        print(\"\\n用戶評分歷史:\")\n",
    "        user_history = user_ratings.join(self.products_df, \"product_id\") \\\n",
    "                                  .select(\"product_name\", \"category\", \"rating\") \\\n",
    "                                  .orderBy(col(\"rating\").desc())\n",
    "        user_history.show(10)\n",
    "        \n",
    "        # 生成推薦\n",
    "        user_df = self.spark.createDataFrame([(user_id,)], [\"user_id\"])\n",
    "        user_recommendations = self.model.recommendForUserSubset(user_df, num_recommendations)\n",
    "        \n",
    "        # 解析推薦結果\n",
    "        recommendations = user_recommendations.select(\"user_id\", \"recommendations\").collect()[0]\n",
    "        \n",
    "        print(f\"\\n為用戶 {user_id} 推薦的商品:\")\n",
    "        \n",
    "        recommended_products = []\n",
    "        for rec in recommendations['recommendations']:\n",
    "            product_id = rec['product_id']\n",
    "            predicted_rating = rec['rating']\n",
    "            \n",
    "            # 獲取商品資訊\n",
    "            product_info = self.products_df.filter(col(\"product_id\") == product_id).collect()[0]\n",
    "            \n",
    "            recommended_products.append({\n",
    "                'product_id': product_id,\n",
    "                'product_name': product_info['product_name'],\n",
    "                'category': product_info['category'],\n",
    "                'price': product_info['price'],\n",
    "                'predicted_rating': predicted_rating\n",
    "            })\n",
    "        \n",
    "        # 顯示推薦結果\n",
    "        rec_df = self.spark.createDataFrame(recommended_products)\n",
    "        rec_df.show(num_recommendations, truncate=False)\n",
    "        \n",
    "        return recommended_products\n",
    "    \n",
    "    def analyze_recommendations(self):\n",
    "        \"\"\"\n",
    "        分析推薦系統的整體表現\n",
    "        \"\"\"\n",
    "        print(\"\\n=== 推薦系統分析 ===\")\n",
    "        \n",
    "        # 為多個用戶生成推薦\n",
    "        sample_users = self.ratings_df.select(\"user_id\").distinct().limit(10).rdd.map(lambda x: x[0]).collect()\n",
    "        \n",
    "        print(f\"為 {len(sample_users)} 個用戶生成推薦...\")\n",
    "        \n",
    "        all_recommendations = []\n",
    "        for user_id in sample_users:\n",
    "            recommendations = self.generate_recommendations(user_id, 5)\n",
    "            all_recommendations.extend(recommendations)\n",
    "        \n",
    "        # 分析推薦的多樣性\n",
    "        recommended_categories = defaultdict(int)\n",
    "        for rec in all_recommendations:\n",
    "            recommended_categories[rec['category']] += 1\n",
    "        \n",
    "        print(\"\\n推薦分類分佈:\")\n",
    "        for category, count in sorted(recommended_categories.items(), key=lambda x: x[1], reverse=True):\n",
    "            print(f\"  {category}: {count} 次推薦\")\n",
    "        \n",
    "        # 分析推薦的價格分佈\n",
    "        recommended_prices = [rec['price'] for rec in all_recommendations]\n",
    "        \n",
    "        print(\"\\n推薦價格統計:\")\n",
    "        print(f\"  平均價格: ${np.mean(recommended_prices):.2f}\")\n",
    "        print(f\"  價格中位數: ${np.median(recommended_prices):.2f}\")\n",
    "        print(f\"  最低價格: ${np.min(recommended_prices):.2f}\")\n",
    "        print(f\"  最高價格: ${np.max(recommended_prices):.2f}\")\n",
    "        \n",
    "        # 視覺化推薦分析\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "        \n",
    "        # 推薦分類分佈\n",
    "        categories = list(recommended_categories.keys())\n",
    "        counts = list(recommended_categories.values())\n",
    "        \n",
    "        axes[0].bar(categories, counts)\n",
    "        axes[0].set_title('推薦分類分佈')\n",
    "        axes[0].set_xlabel('分類')\n",
    "        axes[0].set_ylabel('推薦次數')\n",
    "        axes[0].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # 推薦價格分佈\n",
    "        axes[1].hist(recommended_prices, bins=20, alpha=0.7)\n",
    "        axes[1].set_title('推薦價格分佈')\n",
    "        axes[1].set_xlabel('價格 ($)')\n",
    "        axes[1].set_ylabel('頻率')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return all_recommendations\n",
    "    \n",
    "    def evaluate_recommendation_quality(self):\n",
    "        \"\"\"\n",
    "        評估推薦系統品質\n",
    "        \"\"\"\n",
    "        print(\"\\n=== 推薦系統品質評估 ===\")\n",
    "        \n",
    "        # 計算覆蓋率（推薦系統能推薦多少比例的商品）\n",
    "        total_products = self.products_df.count()\n",
    "        \n",
    "        # 為所有用戶生成推薦\n",
    "        all_users = self.ratings_df.select(\"user_id\").distinct()\n",
    "        all_recommendations = self.model.recommendForAllUsers(5)\n",
    "        \n",
    "        # 提取所有被推薦的商品\n",
    "        recommended_products = all_recommendations.select(\n",
    "            explode(\"recommendations\").alias(\"recommendation\")\n",
    "        ).select(\n",
    "            col(\"recommendation.product_id\").alias(\"product_id\")\n",
    "        ).distinct()\n",
    "        \n",
    "        coverage = recommended_products.count() / total_products\n",
    "        print(f\"商品覆蓋率: {coverage:.2%}\")\n",
    "        \n",
    "        # 計算推薦的多樣性\n",
    "        category_diversity = recommended_products.join(\n",
    "            self.products_df, \"product_id\"\n",
    "        ).select(\"category\").distinct().count()\n",
    "        \n",
    "        total_categories = self.products_df.select(\"category\").distinct().count()\n",
    "        diversity = category_diversity / total_categories\n",
    "        \n",
    "        print(f\"分類多樣性: {diversity:.2%}\")\n",
    "        \n",
    "        # 計算新穎性（推薦不太受歡迎的商品的能力）\n",
    "        product_popularity = self.ratings_df.groupBy(\"product_id\").count().alias(\"popularity\")\n",
    "        \n",
    "        recommended_popularity = recommended_products.join(\n",
    "            product_popularity, \"product_id\"\n",
    "        ).select(\"count\")\n",
    "        \n",
    "        avg_recommended_popularity = recommended_popularity.agg(avg(\"count\")).collect()[0][0]\n",
    "        avg_overall_popularity = product_popularity.agg(avg(\"count\")).collect()[0][0]\n",
    "        \n",
    "        novelty = 1 - (avg_recommended_popularity / avg_overall_popularity)\n",
    "        print(f\"新穎性指標: {novelty:.2%}\")\n",
    "        \n",
    "        # 生成品質報告\n",
    "        quality_metrics = {\n",
    "            'coverage': coverage,\n",
    "            'diversity': diversity,\n",
    "            'novelty': novelty\n",
    "        }\n",
    "        \n",
    "        print(\"\\n📊 推薦系統品質總結:\")\n",
    "        print(f\"  覆蓋率: {coverage:.2%} (推薦了 {coverage*100:.1f}% 的商品)\")\n",
    "        print(f\"  多樣性: {diversity:.2%} (覆蓋了 {diversity*100:.1f}% 的分類)\")\n",
    "        print(f\"  新穎性: {novelty:.2%} (傾向推薦 {'較不受歡迎' if novelty > 0 else '較受歡迎'} 的商品)\")\n",
    "        \n",
    "        # 整體品質評分\n",
    "        overall_quality = (coverage + diversity + abs(novelty)) / 3\n",
    "        print(f\"  整體品質評分: {overall_quality:.2%}\")\n",
    "        \n",
    "        return quality_metrics\n",
    "\n",
    "# 執行推薦系統\n",
    "print(\"\\n=== 專案三：推薦系統 ===\")\n",
    "\n",
    "recommendation_system = RecommendationSystem(spark)\n",
    "ratings_data, products_data, users_data = recommendation_system.generate_sample_data()\n",
    "\n",
    "# 顯示樣本資料\n",
    "print(\"\\n評分資料樣本:\")\n",
    "ratings_data.show(10)\n",
    "\n",
    "print(\"\\n商品資料樣本:\")\n",
    "products_data.show(10)\n",
    "\n",
    "# 執行推薦系統分析\n",
    "popular_products, category_preference = recommendation_system.exploratory_analysis()\n",
    "model, rmse = recommendation_system.build_recommendation_model()\n",
    "\n",
    "# 為幾個用戶生成推薦\n",
    "sample_user_ids = [1, 10, 50, 100]\n",
    "for user_id in sample_user_ids:\n",
    "    recommendations = recommendation_system.generate_recommendations(user_id, 5)\n",
    "\n",
    "# 分析推薦系統整體表現\n",
    "all_recommendations = recommendation_system.analyze_recommendations()\n",
    "quality_metrics = recommendation_system.evaluate_recommendation_quality()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 總結\n",
    "\n",
    "本章通過三個實戰專案展示了 Spark 在不同領域的應用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 實戰專案總結\n",
    "def projects_summary():\n",
    "    \"\"\"\n",
    "    實戰專案總結\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"實戰專案總結\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    projects = {\n",
    "        \"專案一：日誌分析系統\": {\n",
    "            \"核心技術\": [\n",
    "                \"日誌解析和資料清理\",\n",
    "                \"時間序列分析\",\n",
    "                \"異常檢測和安全分析\",\n",
    "                \"資料視覺化\"\n",
    "            ],\n",
    "            \"應用場景\": [\n",
    "                \"網站訪問日誌分析\",\n",
    "                \"安全威脅檢測\",\n",
    "                \"系統性能監控\",\n",
    "                \"用戶行為分析\"\n",
    "            ],\n",
    "            \"關鍵收穫\": [\n",
    "                \"學會處理半結構化資料\",\n",
    "                \"掌握異常檢測技術\",\n",
    "                \"了解安全分析方法\",\n",
    "                \"熟悉時間序列處理\"\n",
    "            ]\n",
    "        },\n",
    "        \"專案二：即時監控系統\": {\n",
    "            \"核心技術\": [\n",
    "                \"即時資料處理\",\n",
    "                \"閾值監控和警報\",\n",
    "                \"趨勢分析\",\n",
    "                \"健康度評估\"\n",
    "            ],\n",
    "            \"應用場景\": [\n",
    "                \"系統監控\",\n",
    "                \"應用程式監控\",\n",
    "                \"基礎設施監控\",\n",
    "                \"業務指標監控\"\n",
    "            ],\n",
    "            \"關鍵收穫\": [\n",
    "                \"掌握即時監控技術\",\n",
    "                \"學會設計警報系統\",\n",
    "                \"了解趨勢分析方法\",\n",
    "                \"熟悉系統健康評估\"\n",
    "            ]\n",
    "        },\n",
    "        \"專案三：推薦系統\": {\n",
    "            \"核心技術\": [\n",
    "                \"協同過濾演算法\",\n",
    "                \"矩陣分解 (ALS)\",\n",
    "                \"推薦品質評估\",\n",
    "                \"個性化推薦\"\n",
    "            ],\n",
    "            \"應用場景\": [\n",
    "                \"電商商品推薦\",\n",
    "                \"內容推薦\",\n",
    "                \"社交網絡推薦\",\n",
    "                \"廣告推薦\"\n",
    "            ],\n",
    "            \"關鍵收穫\": [\n",
    "                \"掌握推薦系統原理\",\n",
    "                \"學會使用 MLlib ALS\",\n",
    "                \"了解推薦評估指標\",\n",
    "                \"熟悉大規模推薦系統\"\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    for project_name, details in projects.items():\n",
    "        print(f\"\\n{project_name}:\")\n",
    "        print(\"-\" * len(project_name))\n",
    "        \n",
    "        for category, items in details.items():\n",
    "            print(f\"\\n{category}:\")\n",
    "            for item in items:\n",
    "                print(f\"  • {item}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"整體學習成果\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    achievements = {\n",
    "        \"技術能力\": [\n",
    "            \"熟練掌握 Spark 核心 API\",\n",
    "            \"具備大資料處理能力\",\n",
    "            \"掌握機器學習應用\",\n",
    "            \"具備系統設計思維\"\n",
    "        ],\n",
    "        \"實戰經驗\": [\n",
    "            \"完成端到端專案開發\",\n",
    "            \"解決實際業務問題\",\n",
    "            \"掌握性能優化技巧\",\n",
    "            \"具備問題診斷能力\"\n",
    "        ],\n",
    "        \"領域知識\": [\n",
    "            \"日誌分析和安全監控\",\n",
    "            \"系統監控和運維\",\n",
    "            \"推薦系統和機器學習\",\n",
    "            \"資料科學和分析\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    for category, items in achievements.items():\n",
    "        print(f\"\\n{category}:\")\n",
    "        for item in items:\n",
    "            print(f\"  ✓ {item}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"下一步建議\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    next_steps = [\n",
    "        \"在實際項目中應用所學技能\",\n",
    "        \"深入學習特定領域的進階技術\",\n",
    "        \"探索 Spark 的新特性和更新\",\n",
    "        \"學習相關的大資料生態系統工具\",\n",
    "        \"參與開源項目，貢獻社區\",\n",
    "        \"持續關注技術發展趨勢\"\n",
    "    ]\n",
    "    \n",
    "    for i, step in enumerate(next_steps, 1):\n",
    "        print(f\"  {i}. {step}\")\n",
    "    \n",
    "    print(\"\\n🎉 恭喜您完成了 Spark 101 的所有課程！\")\n",
    "    print(\"您現在具備了使用 Apache Spark 解決實際問題的能力。\")\n",
    "    print(\"繼續學習，不斷實踐，成為大資料處理專家！\")\n",
    "\n",
    "# 執行總結\n",
    "projects_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 清理資源\n",
    "print(\"\\n清理資源...\")\n",
    "spark.stop()\n",
    "print(\"Spark 會話已結束\")\n",
    "print(\"\\n感謝您完成所有實戰專案！\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}