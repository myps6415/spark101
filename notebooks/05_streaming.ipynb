{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第5章：Spark Streaming 實戰指南\n",
    "\n",
    "本章節將深入學習 Spark Streaming，包括結構化串流、實時數據處理、視窗操作等。\n",
    "\n",
    "## 學習目標\n",
    "- 理解 Spark Streaming 的核心概念\n",
    "- 掌握結構化串流 (Structured Streaming) 的使用\n",
    "- 學習實時數據處理和視窗操作\n",
    "- 實戰各種數據源的串流處理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 環境設置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "import time\n",
    "import json\n",
    "import threading\n",
    "import random\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 創建 SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"SparkStreaming學習\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
    "    .config(\"spark.sql.streaming.checkpointLocation\", \"/tmp/spark-checkpoints\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# 設置日志級別\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "\n",
    "print(f\"Spark版本: {spark.version}\")\n",
    "print(f\"Spark UI: http://localhost:4040\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 結構化串流基礎"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 創建模擬數據生成器\n",
    "import os\n",
    "import tempfile\n",
    "import shutil\n",
    "\n",
    "# 創建臨時目錄\n",
    "temp_dir = tempfile.mkdtemp()\n",
    "input_dir = os.path.join(temp_dir, \"input\")\n",
    "output_dir = os.path.join(temp_dir, \"output\")\n",
    "checkpoint_dir = os.path.join(temp_dir, \"checkpoint\")\n",
    "\n",
    "os.makedirs(input_dir, exist_ok=True)\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "print(f\"臨時目錄: {temp_dir}\")\n",
    "print(f\"輸入目錄: {input_dir}\")\n",
    "print(f\"輸出目錄: {output_dir}\")\n",
    "print(f\"檢查點目錄: {checkpoint_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 文件串流處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義數據模式\n",
    "schema = StructType([\n",
    "    StructField(\"timestamp\", StringType(), True),\n",
    "    StructField(\"user_id\", StringType(), True),\n",
    "    StructField(\"event_type\", StringType(), True),\n",
    "    StructField(\"value\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "# 創建文件串流\n",
    "file_stream = spark.readStream \\\n",
    "    .format(\"json\") \\\n",
    "    .schema(schema) \\\n",
    "    .option(\"path\", input_dir) \\\n",
    "    .load()\n",
    "\n",
    "print(\"文件串流創建完成\")\n",
    "print(\"Schema:\")\n",
    "file_stream.printSchema()\n",
    "print(f\"是否為串流: {file_stream.isStreaming}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 創建數據生成器函數\n",
    "def generate_sample_data(filename, num_records=10):\n",
    "    \"\"\"生成樣本數據\"\"\"\n",
    "    data = []\n",
    "    event_types = ['click', 'view', 'purchase', 'login']\n",
    "    user_ids = [f'user_{i}' for i in range(1, 21)]\n",
    "    \n",
    "    for i in range(num_records):\n",
    "        record = {\n",
    "            \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            \"user_id\": random.choice(user_ids),\n",
    "            \"event_type\": random.choice(event_types),\n",
    "            \"value\": random.randint(1, 100)\n",
    "        }\n",
    "        data.append(record)\n",
    "    \n",
    "    # 寫入文件\n",
    "    filepath = os.path.join(input_dir, filename)\n",
    "    with open(filepath, 'w') as f:\n",
    "        for record in data:\n",
    "            f.write(json.dumps(record) + '\\n')\n",
    "    \n",
    "    print(f\"生成 {num_records} 條記錄到 {filename}\")\n",
    "    return len(data)\n",
    "\n",
    "# 生成初始數據\n",
    "generate_sample_data(\"initial_data.json\", 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基本串流處理\n",
    "basic_query = file_stream.writeStream \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .format(\"console\") \\\n",
    "    .trigger(processingTime='10 seconds') \\\n",
    "    .option(\"truncate\", \"false\") \\\n",
    "    .start()\n",
    "\n",
    "print(\"基本串流處理已啟動\")\n",
    "print(f\"查詢 ID: {basic_query.id}\")\n",
    "print(f\"查詢狀態: {basic_query.status}\")\n",
    "\n",
    "# 等待一段時間\n",
    "time.sleep(15)\n",
    "\n",
    "# 添加更多數據\n",
    "generate_sample_data(\"batch_2.json\", 10)\n",
    "\n",
    "# 再等待一段時間\n",
    "time.sleep(10)\n",
    "\n",
    "# 停止查詢\n",
    "basic_query.stop()\n",
    "print(\"基本串流處理已停止\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 聚合和轉換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 聚合查詢\n",
    "aggregated_stream = file_stream.groupBy(\"event_type\") \\\n",
    "    .agg(\n",
    "        count(\"*\").alias(\"event_count\"),\n",
    "        avg(\"value\").alias(\"avg_value\"),\n",
    "        max(\"value\").alias(\"max_value\"),\n",
    "        min(\"value\").alias(\"min_value\")\n",
    "    )\n",
    "\n",
    "# 啟動聚合查詢\n",
    "agg_query = aggregated_stream.writeStream \\\n",
    "    .outputMode(\"complete\") \\\n",
    "    .format(\"console\") \\\n",
    "    .trigger(processingTime='10 seconds') \\\n",
    "    .option(\"truncate\", \"false\") \\\n",
    "    .start()\n",
    "\n",
    "print(\"聚合查詢已啟動\")\n",
    "\n",
    "# 連續添加數據\n",
    "for i in range(3):\n",
    "    time.sleep(5)\n",
    "    generate_sample_data(f\"batch_{i+3}.json\", 15)\n",
    "    print(f\"添加了第 {i+3} 批數據\")\n",
    "\n",
    "# 等待處理完成\n",
    "time.sleep(15)\n",
    "\n",
    "# 停止查詢\n",
    "agg_query.stop()\n",
    "print(\"聚合查詢已停止\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 視窗操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 時間視窗聚合\n",
    "windowed_stream = file_stream \\\n",
    "    .withColumn(\"timestamp\", to_timestamp(col(\"timestamp\"), \"yyyy-MM-dd HH:mm:ss\")) \\\n",
    "    .withWatermark(\"timestamp\", \"10 seconds\") \\\n",
    "    .groupBy(\n",
    "        window(col(\"timestamp\"), \"30 seconds\", \"10 seconds\"),\n",
    "        col(\"event_type\")\n",
    "    ) \\\n",
    "    .agg(\n",
    "        count(\"*\").alias(\"event_count\"),\n",
    "        avg(\"value\").alias(\"avg_value\")\n",
    "    ) \\\n",
    "    .select(\n",
    "        col(\"window.start\").alias(\"window_start\"),\n",
    "        col(\"window.end\").alias(\"window_end\"),\n",
    "        col(\"event_type\"),\n",
    "        col(\"event_count\"),\n",
    "        round(col(\"avg_value\"), 2).alias(\"avg_value\")\n",
    "    )\n",
    "\n",
    "# 啟動視窗查詢\n",
    "window_query = windowed_stream.writeStream \\\n",
    "    .outputMode(\"update\") \\\n",
    "    .format(\"console\") \\\n",
    "    .trigger(processingTime='5 seconds') \\\n",
    "    .option(\"truncate\", \"false\") \\\n",
    "    .start()\n",
    "\n",
    "print(\"視窗查詢已啟動\")\n",
    "\n",
    "# 連續添加數據測試視窗\n",
    "for i in range(4):\n",
    "    time.sleep(8)\n",
    "    generate_sample_data(f\"window_batch_{i+1}.json\", 12)\n",
    "    print(f\"添加了視窗測試數據 {i+1}\")\n",
    "\n",
    "# 等待處理完成\n",
    "time.sleep(20)\n",
    "\n",
    "# 停止查詢\n",
    "window_query.stop()\n",
    "print(\"視窗查詢已停止\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 過濾和轉換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 複雜轉換和過濾\n",
    "transformed_stream = file_stream \\\n",
    "    .withColumn(\"timestamp\", to_timestamp(col(\"timestamp\"), \"yyyy-MM-dd HH:mm:ss\")) \\\n",
    "    .withColumn(\"hour\", hour(col(\"timestamp\"))) \\\n",
    "    .withColumn(\"value_category\", \n",
    "                when(col(\"value\") >= 80, \"high\")\n",
    "                .when(col(\"value\") >= 50, \"medium\")\n",
    "                .otherwise(\"low\")) \\\n",
    "    .withColumn(\"is_high_value\", col(\"value\") >= 75) \\\n",
    "    .filter(col(\"event_type\").isin([\"click\", \"purchase\"])) \\\n",
    "    .select(\n",
    "        col(\"timestamp\"),\n",
    "        col(\"user_id\"),\n",
    "        col(\"event_type\"),\n",
    "        col(\"value\"),\n",
    "        col(\"hour\"),\n",
    "        col(\"value_category\"),\n",
    "        col(\"is_high_value\")\n",
    "    )\n",
    "\n",
    "# 啟動轉換查詢\n",
    "transform_query = transformed_stream.writeStream \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .format(\"console\") \\\n",
    "    .trigger(processingTime='8 seconds') \\\n",
    "    .option(\"truncate\", \"false\") \\\n",
    "    .start()\n",
    "\n",
    "print(\"轉換查詢已啟動\")\n",
    "\n",
    "# 添加測試數據\n",
    "for i in range(3):\n",
    "    time.sleep(6)\n",
    "    generate_sample_data(f\"transform_batch_{i+1}.json\", 8)\n",
    "    print(f\"添加了轉換測試數據 {i+1}\")\n",
    "\n",
    "# 等待處理完成\n",
    "time.sleep(15)\n",
    "\n",
    "# 停止查詢\n",
    "transform_query.stop()\n",
    "print(\"轉換查詢已停止\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 多個輸出目標"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 創建多個查詢同時處理\n",
    "# 查詢1：保存到文件\n",
    "file_output_query = file_stream.writeStream \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .format(\"json\") \\\n",
    "    .option(\"path\", output_dir) \\\n",
    "    .option(\"checkpointLocation\", checkpoint_dir + \"/file_output\") \\\n",
    "    .trigger(processingTime='10 seconds') \\\n",
    "    .start()\n",
    "\n",
    "# 查詢2：實時統計\n",
    "stats_query = file_stream.groupBy(\"event_type\", \"user_id\") \\\n",
    "    .agg(\n",
    "        count(\"*\").alias(\"event_count\"),\n",
    "        sum(\"value\").alias(\"total_value\")\n",
    "    ) \\\n",
    "    .writeStream \\\n",
    "    .outputMode(\"complete\") \\\n",
    "    .format(\"console\") \\\n",
    "    .trigger(processingTime='10 seconds') \\\n",
    "    .start()\n",
    "\n",
    "print(\"多個查詢已啟動\")\n",
    "print(f\"文件輸出查詢 ID: {file_output_query.id}\")\n",
    "print(f\"統計查詢 ID: {stats_query.id}\")\n",
    "\n",
    "# 添加數據\n",
    "for i in range(3):\n",
    "    time.sleep(8)\n",
    "    generate_sample_data(f\"multi_output_{i+1}.json\", 10)\n",
    "    print(f\"添加了多輸出測試數據 {i+1}\")\n",
    "\n",
    "# 等待處理完成\n",
    "time.sleep(15)\n",
    "\n",
    "# 停止所有查詢\n",
    "file_output_query.stop()\n",
    "stats_query.stop()\n",
    "print(\"所有查詢已停止\")\n",
    "\n",
    "# 檢查輸出文件\n",
    "output_files = os.listdir(output_dir)\n",
    "print(f\"\\n輸出文件: {output_files}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 狀態管理和容錯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 帶狀態的查詢\n",
    "stateful_stream = file_stream \\\n",
    "    .groupBy(\"user_id\") \\\n",
    "    .agg(\n",
    "        count(\"*\").alias(\"total_events\"),\n",
    "        sum(\"value\").alias(\"total_value\"),\n",
    "        avg(\"value\").alias(\"avg_value\"),\n",
    "        collect_list(\"event_type\").alias(\"event_types\")\n",
    "    ) \\\n",
    "    .withColumn(\"avg_value\", round(col(\"avg_value\"), 2))\n",
    "\n",
    "# 啟動狀態查詢\n",
    "stateful_query = stateful_stream.writeStream \\\n",
    "    .outputMode(\"complete\") \\\n",
    "    .format(\"console\") \\\n",
    "    .option(\"checkpointLocation\", checkpoint_dir + \"/stateful\") \\\n",
    "    .trigger(processingTime='10 seconds') \\\n",
    "    .option(\"truncate\", \"false\") \\\n",
    "    .start()\n",
    "\n",
    "print(\"狀態查詢已啟動\")\n",
    "\n",
    "# 模擬數據添加\n",
    "for i in range(4):\n",
    "    time.sleep(8)\n",
    "    generate_sample_data(f\"stateful_batch_{i+1}.json\", 6)\n",
    "    print(f\"添加了狀態測試數據 {i+1}\")\n",
    "\n",
    "# 等待處理完成\n",
    "time.sleep(15)\n",
    "\n",
    "# 查看查詢統計\n",
    "print(\"\\n查詢進度:\")\n",
    "print(stateful_query.lastProgress)\n",
    "\n",
    "# 停止查詢\n",
    "stateful_query.stop()\n",
    "print(\"狀態查詢已停止\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 實時數據品質監控"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 數據品質監控\n",
    "quality_stream = file_stream \\\n",
    "    .withColumn(\"timestamp\", to_timestamp(col(\"timestamp\"), \"yyyy-MM-dd HH:mm:ss\")) \\\n",
    "    .withColumn(\"is_valid_timestamp\", col(\"timestamp\").isNotNull()) \\\n",
    "    .withColumn(\"is_valid_user\", col(\"user_id\").isNotNull() & (length(col(\"user_id\")) > 0)) \\\n",
    "    .withColumn(\"is_valid_event\", col(\"event_type\").isin([\"click\", \"view\", \"purchase\", \"login\"])) \\\n",
    "    .withColumn(\"is_valid_value\", (col(\"value\") >= 0) & (col(\"value\") <= 100)) \\\n",
    "    .withColumn(\"is_valid_record\", \n",
    "                col(\"is_valid_timestamp\") & \n",
    "                col(\"is_valid_user\") & \n",
    "                col(\"is_valid_event\") & \n",
    "                col(\"is_valid_value\"))\n",
    "\n",
    "# 品質統計\n",
    "quality_stats = quality_stream.agg(\n",
    "    count(\"*\").alias(\"total_records\"),\n",
    "    sum(when(col(\"is_valid_record\"), 1).otherwise(0)).alias(\"valid_records\"),\n",
    "    sum(when(col(\"is_valid_timestamp\"), 1).otherwise(0)).alias(\"valid_timestamps\"),\n",
    "    sum(when(col(\"is_valid_user\"), 1).otherwise(0)).alias(\"valid_users\"),\n",
    "    sum(when(col(\"is_valid_event\"), 1).otherwise(0)).alias(\"valid_events\"),\n",
    "    sum(when(col(\"is_valid_value\"), 1).otherwise(0)).alias(\"valid_values\")\n",
    ") \\\n",
    ".withColumn(\"data_quality_score\", \n",
    "            round(col(\"valid_records\") / col(\"total_records\") * 100, 2))\n",
    "\n",
    "# 啟動品質監控\n",
    "quality_query = quality_stats.writeStream \\\n",
    "    .outputMode(\"complete\") \\\n",
    "    .format(\"console\") \\\n",
    "    .trigger(processingTime='10 seconds') \\\n",
    "    .option(\"truncate\", \"false\") \\\n",
    "    .start()\n",
    "\n",
    "print(\"數據品質監控已啟動\")\n",
    "\n",
    "# 添加測試數據（包含一些無效數據）\n",
    "def generate_quality_test_data(filename, num_records=10):\n",
    "    \"\"\"生成包含品質問題的測試數據\"\"\"\n",
    "    data = []\n",
    "    event_types = ['click', 'view', 'purchase', 'login', 'invalid_event']  # 包含無效事件\n",
    "    user_ids = [f'user_{i}' for i in range(1, 16)] + ['', None]  # 包含無效用戶\n",
    "    \n",
    "    for i in range(num_records):\n",
    "        # 隨機生成一些無效數據\n",
    "        timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\") if random.random() > 0.1 else None\n",
    "        user_id = random.choice(user_ids)\n",
    "        event_type = random.choice(event_types)\n",
    "        value = random.randint(-10, 110)  # 包含超出範圍的值\n",
    "        \n",
    "        record = {\n",
    "            \"timestamp\": timestamp,\n",
    "            \"user_id\": user_id,\n",
    "            \"event_type\": event_type,\n",
    "            \"value\": value\n",
    "        }\n",
    "        data.append(record)\n",
    "    \n",
    "    # 寫入文件\n",
    "    filepath = os.path.join(input_dir, filename)\n",
    "    with open(filepath, 'w') as f:\n",
    "        for record in data:\n",
    "            f.write(json.dumps(record) + '\\n')\n",
    "    \n",
    "    print(f\"生成 {num_records} 條品質測試記錄到 {filename}\")\n",
    "    return len(data)\n",
    "\n",
    "# 添加品質測試數據\n",
    "for i in range(3):\n",
    "    time.sleep(8)\n",
    "    generate_quality_test_data(f\"quality_test_{i+1}.json\", 12)\n",
    "    print(f\"添加了品質測試數據 {i+1}\")\n",
    "\n",
    "# 等待處理完成\n",
    "time.sleep(15)\n",
    "\n",
    "# 停止查詢\n",
    "quality_query.stop()\n",
    "print(\"數據品質監控已停止\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 實時告警系統"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 創建告警邏輯\n",
    "def create_alert_stream():\n",
    "    \"\"\"創建實時告警流\"\"\"\n",
    "    # 高價值事件告警\n",
    "    high_value_alerts = file_stream \\\n",
    "        .filter(col(\"value\") >= 90) \\\n",
    "        .withColumn(\"alert_type\", lit(\"HIGH_VALUE_EVENT\")) \\\n",
    "        .withColumn(\"alert_message\", \n",
    "                   concat(lit(\"High value event detected: \"), \n",
    "                         col(\"event_type\"), lit(\" with value \"), col(\"value\")))\n",
    "    \n",
    "    # 頻繁用戶活動告警\n",
    "    frequent_user_alerts = file_stream \\\n",
    "        .withColumn(\"timestamp\", to_timestamp(col(\"timestamp\"), \"yyyy-MM-dd HH:mm:ss\")) \\\n",
    "        .withWatermark(\"timestamp\", \"30 seconds\") \\\n",
    "        .groupBy(\n",
    "            window(col(\"timestamp\"), \"1 minute\"),\n",
    "            col(\"user_id\")\n",
    "        ) \\\n",
    "        .count() \\\n",
    "        .filter(col(\"count\") >= 5) \\\n",
    "        .withColumn(\"alert_type\", lit(\"FREQUENT_USER_ACTIVITY\")) \\\n",
    "        .withColumn(\"alert_message\", \n",
    "                   concat(lit(\"Frequent activity detected for user \"), \n",
    "                         col(\"user_id\"), lit(\": \"), col(\"count\"), lit(\" events in 1 minute\")))\n",
    "    \n",
    "    return high_value_alerts, frequent_user_alerts\n",
    "\n",
    "# 創建告警流\n",
    "high_value_alerts, frequent_user_alerts = create_alert_stream()\n",
    "\n",
    "# 啟動高價值告警\n",
    "high_value_query = high_value_alerts.select(\n",
    "    col(\"timestamp\"),\n",
    "    col(\"user_id\"),\n",
    "    col(\"event_type\"),\n",
    "    col(\"value\"),\n",
    "    col(\"alert_type\"),\n",
    "    col(\"alert_message\")\n",
    ").writeStream \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .format(\"console\") \\\n",
    "    .trigger(processingTime='5 seconds') \\\n",
    "    .option(\"truncate\", \"false\") \\\n",
    "    .start()\n",
    "\n",
    "print(\"告警系統已啟動\")\n",
    "\n",
    "# 生成觸發告警的數據\n",
    "def generate_alert_data(filename, num_records=10):\n",
    "    \"\"\"生成會觸發告警的數據\"\"\"\n",
    "    data = []\n",
    "    event_types = ['click', 'view', 'purchase', 'login']\n",
    "    \n",
    "    # 生成高價值事件\n",
    "    for i in range(num_records // 2):\n",
    "        record = {\n",
    "            \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            \"user_id\": f'user_{random.randint(1, 5)}',\n",
    "            \"event_type\": random.choice(event_types),\n",
    "            \"value\": random.randint(85, 100)  # 高價值\n",
    "        }\n",
    "        data.append(record)\n",
    "    \n",
    "    # 生成頻繁用戶活動\n",
    "    frequent_user = 'user_frequent'\n",
    "    for i in range(num_records // 2):\n",
    "        record = {\n",
    "            \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            \"user_id\": frequent_user,\n",
    "            \"event_type\": random.choice(event_types),\n",
    "            \"value\": random.randint(30, 70)\n",
    "        }\n",
    "        data.append(record)\n",
    "    \n",
    "    # 寫入文件\n",
    "    filepath = os.path.join(input_dir, filename)\n",
    "    with open(filepath, 'w') as f:\n",
    "        for record in data:\n",
    "            f.write(json.dumps(record) + '\\n')\n",
    "    \n",
    "    print(f\"生成 {num_records} 條告警測試記錄到 {filename}\")\n",
    "    return len(data)\n",
    "\n",
    "# 添加告警測試數據\n",
    "for i in range(3):\n",
    "    time.sleep(6)\n",
    "    generate_alert_data(f\"alert_test_{i+1}.json\", 8)\n",
    "    print(f\"添加了告警測試數據 {i+1}\")\n",
    "\n",
    "# 等待處理完成\n",
    "time.sleep(15)\n",
    "\n",
    "# 停止查詢\n",
    "high_value_query.stop()\n",
    "print(\"告警系統已停止\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. 查詢管理和監控"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 創建監控查詢\n",
    "monitoring_stream = file_stream.agg(\n",
    "    count(\"*\").alias(\"total_records\"),\n",
    "    countDistinct(\"user_id\").alias(\"unique_users\"),\n",
    "    countDistinct(\"event_type\").alias(\"unique_events\"),\n",
    "    avg(\"value\").alias(\"avg_value\"),\n",
    "    min(\"value\").alias(\"min_value\"),\n",
    "    max(\"value\").alias(\"max_value\")\n",
    ") \\\n",
    ".withColumn(\"avg_value\", round(col(\"avg_value\"), 2)) \\\n",
    ".withColumn(\"processing_time\", current_timestamp())\n",
    "\n",
    "# 啟動監控查詢\n",
    "monitoring_query = monitoring_stream.writeStream \\\n",
    "    .outputMode(\"complete\") \\\n",
    "    .format(\"console\") \\\n",
    "    .trigger(processingTime='10 seconds') \\\n",
    "    .option(\"truncate\", \"false\") \\\n",
    "    .start()\n",
    "\n",
    "print(\"監控查詢已啟動\")\n",
    "print(f\"查詢 ID: {monitoring_query.id}\")\n",
    "print(f\"查詢名稱: {monitoring_query.name}\")\n",
    "\n",
    "# 添加監控測試數據\n",
    "for i in range(3):\n",
    "    time.sleep(8)\n",
    "    generate_sample_data(f\"monitoring_test_{i+1}.json\", 15)\n",
    "    \n",
    "    # 顯示查詢狀態\n",
    "    print(f\"\\n=== 查詢狀態 {i+1} ===\")\n",
    "    print(f\"查詢狀態: {monitoring_query.status}\")\n",
    "    print(f\"最近進度: {monitoring_query.lastProgress}\")\n",
    "\n",
    "# 等待處理完成\n",
    "time.sleep(15)\n",
    "\n",
    "# 獲取最終統計\n",
    "final_progress = monitoring_query.lastProgress\n",
    "print(\"\\n=== 最終統計 ===\")\n",
    "print(f\"處理的批次數: {final_progress.get('batchId', 'N/A')}\")\n",
    "print(f\"輸入行數: {final_progress.get('inputRowsPerSecond', 'N/A')}\")\n",
    "print(f\"處理行數: {final_progress.get('processedRowsPerSecond', 'N/A')}\")\n",
    "\n",
    "# 停止查詢\n",
    "monitoring_query.stop()\n",
    "print(\"監控查詢已停止\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. 自定義輸出接收器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定義輸出函數\n",
    "def custom_output_function(df, epoch_id):\n",
    "    \"\"\"自定義輸出處理函數\"\"\"\n",
    "    print(f\"\\n=== 處理批次 {epoch_id} ===\")\n",
    "    \n",
    "    # 獲取基本統計\n",
    "    count = df.count()\n",
    "    print(f\"記錄數: {count}\")\n",
    "    \n",
    "    if count > 0:\n",
    "        # 顯示樣本數據\n",
    "        print(\"樣本數據:\")\n",
    "        df.show(5, truncate=False)\n",
    "        \n",
    "        # 按事件類型統計\n",
    "        event_stats = df.groupBy(\"event_type\").count().collect()\n",
    "        print(\"事件類型統計:\")\n",
    "        for row in event_stats:\n",
    "            print(f\"  {row.event_type}: {row.count}\")\n",
    "        \n",
    "        # 可以在這裡添加更多自定義處理邏輯\n",
    "        # 例如：發送通知、寫入數據庫、調用API等\n",
    "    \n",
    "    print(f\"批次 {epoch_id} 處理完成\")\n",
    "\n",
    "# 使用自定義輸出\n",
    "custom_query = file_stream.writeStream \\\n",
    "    .foreachBatch(custom_output_function) \\\n",
    "    .trigger(processingTime='10 seconds') \\\n",
    "    .start()\n",
    "\n",
    "print(\"自定義輸出查詢已啟動\")\n",
    "\n",
    "# 添加測試數據\n",
    "for i in range(3):\n",
    "    time.sleep(8)\n",
    "    generate_sample_data(f\"custom_output_{i+1}.json\", 8)\n",
    "    print(f\"添加了自定義輸出測試數據 {i+1}\")\n",
    "\n",
    "# 等待處理完成\n",
    "time.sleep(15)\n",
    "\n",
    "# 停止查詢\n",
    "custom_query.stop()\n",
    "print(\"自定義輸出查詢已停止\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. 性能優化和最佳實踐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 性能優化示例\n",
    "print(\"=== 性能優化示例 ===\")\n",
    "\n",
    "# 1. 合理的觸發間隔\n",
    "optimized_stream = file_stream \\\n",
    "    .repartition(4) \\\n",
    "    .cache() \\\n",
    "    .groupBy(\"event_type\") \\\n",
    "    .agg(\n",
    "        count(\"*\").alias(\"count\"),\n",
    "        avg(\"value\").alias(\"avg_value\")\n",
    "    )\n",
    "\n",
    "# 2. 使用適當的輸出模式\n",
    "perf_query = optimized_stream.writeStream \\\n",
    "    .outputMode(\"complete\") \\\n",
    "    .format(\"console\") \\\n",
    "    .trigger(processingTime='10 seconds') \\\n",
    "    .option(\"checkpointLocation\", checkpoint_dir + \"/performance\") \\\n",
    "    .start()\n",
    "\n",
    "print(\"性能優化查詢已啟動\")\n",
    "\n",
    "# 監控性能指標\n",
    "start_time = time.time()\n",
    "\n",
    "# 添加測試數據\n",
    "for i in range(3):\n",
    "    time.sleep(8)\n",
    "    generate_sample_data(f\"perf_test_{i+1}.json\", 20)\n",
    "    \n",
    "    # 顯示性能指標\n",
    "    progress = perf_query.lastProgress\n",
    "    if progress:\n",
    "        print(f\"\\n批次 {progress.get('batchId', 'N/A')} 性能指標:\")\n",
    "        print(f\"  輸入速率: {progress.get('inputRowsPerSecond', 0):.2f} 行/秒\")\n",
    "        print(f\"  處理速率: {progress.get('processedRowsPerSecond', 0):.2f} 行/秒\")\n",
    "        print(f\"  批次持續時間: {progress.get('batchDuration', 0)} ms\")\n",
    "\n",
    "# 等待處理完成\n",
    "time.sleep(15)\n",
    "\n",
    "# 計算總處理時間\n",
    "total_time = time.time() - start_time\n",
    "print(f\"\\n總處理時間: {total_time:.2f} 秒\")\n",
    "\n",
    "# 停止查詢\n",
    "perf_query.stop()\n",
    "print(\"性能優化查詢已停止\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. 實戰案例：實時儀表板"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 創建實時儀表板\n",
    "def create_dashboard():\n",
    "    \"\"\"創建實時數據儀表板\"\"\"\n",
    "    \n",
    "    # 實時統計\n",
    "    real_time_stats = file_stream \\\n",
    "        .withColumn(\"timestamp\", to_timestamp(col(\"timestamp\"), \"yyyy-MM-dd HH:mm:ss\")) \\\n",
    "        .withColumn(\"hour\", hour(col(\"timestamp\"))) \\\n",
    "        .groupBy(\"hour\", \"event_type\") \\\n",
    "        .agg(\n",
    "            count(\"*\").alias(\"event_count\"),\n",
    "            avg(\"value\").alias(\"avg_value\"),\n",
    "            countDistinct(\"user_id\").alias(\"unique_users\")\n",
    "        ) \\\n",
    "        .withColumn(\"avg_value\", round(col(\"avg_value\"), 2))\n",
    "    \n",
    "    # 用戶活動統計\n",
    "    user_activity = file_stream \\\n",
    "        .groupBy(\"user_id\") \\\n",
    "        .agg(\n",
    "            count(\"*\").alias(\"total_events\"),\n",
    "            sum(\"value\").alias(\"total_value\"),\n",
    "            countDistinct(\"event_type\").alias(\"unique_events\")\n",
    "        ) \\\n",
    "        .filter(col(\"total_events\") >= 3) \\\n",
    "        .orderBy(col(\"total_value\").desc())\n",
    "    \n",
    "    return real_time_stats, user_activity\n",
    "\n",
    "# 創建儀表板查詢\n",
    "stats_stream, user_stream = create_dashboard()\n",
    "\n",
    "# 啟動統計查詢\n",
    "stats_query = stats_stream.writeStream \\\n",
    "    .outputMode(\"complete\") \\\n",
    "    .format(\"console\") \\\n",
    "    .trigger(processingTime='10 seconds') \\\n",
    "    .option(\"truncate\", \"false\") \\\n",
    "    .start()\n",
    "\n",
    "print(\"實時儀表板已啟動\")\n",
    "\n",
    "# 生成儀表板測試數據\n",
    "def generate_dashboard_data(filename, num_records=15):\n",
    "    \"\"\"生成儀表板測試數據\"\"\"\n",
    "    data = []\n",
    "    event_types = ['click', 'view', 'purchase', 'login']\n",
    "    user_ids = [f'user_{i}' for i in range(1, 11)]\n",
    "    \n",
    "    current_time = datetime.now()\n",
    "    \n",
    "    for i in range(num_records):\n",
    "        # 生成不同時間的數據\n",
    "        timestamp = current_time - timedelta(minutes=random.randint(0, 60))\n",
    "        \n",
    "        record = {\n",
    "            \"timestamp\": timestamp.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            \"user_id\": random.choice(user_ids),\n",
    "            \"event_type\": random.choice(event_types),\n",
    "            \"value\": random.randint(10, 90)\n",
    "        }\n",
    "        data.append(record)\n",
    "    \n",
    "    # 寫入文件\n",
    "    filepath = os.path.join(input_dir, filename)\n",
    "    with open(filepath, 'w') as f:\n",
    "        for record in data:\n",
    "            f.write(json.dumps(record) + '\\n')\n",
    "    \n",
    "    print(f\"生成 {num_records} 條儀表板測試記錄到 {filename}\")\n",
    "    return len(data)\n",
    "\n",
    "# 添加儀表板測試數據\n",
    "for i in range(4):\n",
    "    time.sleep(8)\n",
    "    generate_dashboard_data(f\"dashboard_test_{i+1}.json\", 12)\n",
    "    print(f\"添加了儀表板測試數據 {i+1}\")\n",
    "\n",
    "# 等待處理完成\n",
    "time.sleep(15)\n",
    "\n",
    "# 停止查詢\n",
    "stats_query.stop()\n",
    "print(\"實時儀表板已停止\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. 總結和清理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 清理資源\n",
    "print(\"=== Spark Streaming 學習總結 ===\")\n",
    "print(\"✓ 結構化串流基礎概念\")\n",
    "print(\"✓ 文件串流處理\")\n",
    "print(\"✓ 實時聚合和轉換\")\n",
    "print(\"✓ 視窗操作和水印\")\n",
    "print(\"✓ 過濾和複雜轉換\")\n",
    "print(\"✓ 多輸出目標\")\n",
    "print(\"✓ 狀態管理和容錯\")\n",
    "print(\"✓ 數據品質監控\")\n",
    "print(\"✓ 實時告警系統\")\n",
    "print(\"✓ 查詢管理和監控\")\n",
    "print(\"✓ 自定義輸出接收器\")\n",
    "print(\"✓ 性能優化技巧\")\n",
    "print(\"✓ 實時儀表板實戰\")\n",
    "\n",
    "# 停止所有活動查詢\n",
    "active_queries = spark.streams.active\n",
    "print(f\"\\n活動查詢數: {len(active_queries)}\")\n",
    "\n",
    "for query in active_queries:\n",
    "    print(f\"停止查詢: {query.id}\")\n",
    "    query.stop()\n",
    "\n",
    "print(\"所有查詢已停止\")\n",
    "\n",
    "# 清理臨時文件\n",
    "try:\n",
    "    shutil.rmtree(temp_dir)\n",
    "    print(f\"已清理臨時目錄: {temp_dir}\")\n",
    "except:\n",
    "    print(f\"無法清理臨時目錄: {temp_dir}\")\n",
    "\n",
    "# 停止 SparkSession\n",
    "spark.stop()\n",
    "print(\"Spark session 已停止\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 學習重點回顧\n",
    "\n",
    "### 核心概念\n",
    "1. **結構化串流**：基於 DataFrame 的串流處理 API\n",
    "2. **輸出模式**：Append、Complete、Update\n",
    "3. **觸發器**：控制批次處理頻率\n",
    "4. **檢查點**：保證容錯和一致性\n",
    "\n",
    "### 進階特性\n",
    "1. **視窗操作**：時間視窗聚合\n",
    "2. **水印**：處理延遲數據\n",
    "3. **狀態管理**：維護跨批次狀態\n",
    "4. **自定義輸出**：靈活的輸出處理\n",
    "\n",
    "### 實戰應用\n",
    "1. **實時監控**：系統指標、業務指標\n",
    "2. **數據品質**：實時數據驗證\n",
    "3. **告警系統**：異常檢測和通知\n",
    "4. **實時儀表板**：可視化展示\n",
    "\n",
    "### 最佳實踐\n",
    "1. **性能優化**：合理分區、緩存策略\n",
    "2. **容錯機制**：檢查點、重啟策略\n",
    "3. **監控調試**：查詢狀態、性能指標\n",
    "4. **資源管理**：內存配置、並行度調整\n",
    "\n",
    "通過本章學習，您已經掌握了 Spark Streaming 的核心技術，能夠構建高效、可靠的實時數據處理系統。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}