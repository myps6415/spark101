{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第3章：DataFrame 和 Dataset API\n",
    "\n",
    "本章節將深入學習 DataFrame 和 Dataset 的操作，這是 Spark 中最常用的資料結構。\n",
    "\n",
    "## 學習目標\n",
    "- 理解 DataFrame 的概念和優勢\n",
    "- 掌握 DataFrame 的基本操作\n",
    "- 學習 Dataset API 的使用\n",
    "- 了解 Catalyst 優化器的工作原理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 環境設置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, when, lit, upper, lower, substring, concat\n",
    "from pyspark.sql.functions import sum as spark_sum, avg, max as spark_max, min as spark_min, count\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType, TimestampType\n",
    "from datetime import datetime, date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 創建 SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"DataFrame操作學習\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(f\"Spark版本: {spark.version}\")\n",
    "print(f\"Spark UI: http://localhost:4040\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 創建 DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 方法1：從 Python 數據創建\n",
    "employees_data = [\n",
    "    (\"Alice\", 25, \"Engineering\", 75000, datetime(2020, 1, 15)),\n",
    "    (\"Bob\", 30, \"Sales\", 65000, datetime(2019, 3, 20)),\n",
    "    (\"Charlie\", 35, \"Engineering\", 85000, datetime(2018, 7, 10)),\n",
    "    (\"Diana\", 28, \"Marketing\", 60000, datetime(2021, 2, 5)),\n",
    "    (\"Eve\", 32, \"Engineering\", 80000, datetime(2019, 11, 12)),\n",
    "    (\"Frank\", 29, \"Sales\", 70000, datetime(2020, 8, 30)),\n",
    "    (\"Grace\", 26, \"Marketing\", 55000, datetime(2021, 5, 18)),\n",
    "    (\"Henry\", 31, \"Engineering\", 90000, datetime(2017, 4, 22))\n",
    "]\n",
    "\n",
    "columns = [\"name\", \"age\", \"department\", \"salary\", \"hire_date\"]\n",
    "employees_df = spark.createDataFrame(employees_data, columns)\n",
    "\n",
    "print(\"員工資料:\")\n",
    "employees_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 方法2：使用明確的 Schema\n",
    "schema = StructType([\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"age\", IntegerType(), True),\n",
    "    StructField(\"department\", StringType(), True),\n",
    "    StructField(\"salary\", DoubleType(), True),\n",
    "    StructField(\"hire_date\", TimestampType(), True)\n",
    "])\n",
    "\n",
    "employees_df_schema = spark.createDataFrame(employees_data, schema)\n",
    "\n",
    "print(\"DataFrame Schema:\")\n",
    "employees_df_schema.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 基本 DataFrame 操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 選擇特定列\n",
    "print(\"選擇姓名和薪水:\")\n",
    "employees_df.select(\"name\", \"salary\").show()\n",
    "\n",
    "print(\"\\n使用 col() 函數:\")\n",
    "employees_df.select(col(\"name\"), col(\"salary\")).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 過濾操作\n",
    "print(\"薪水大於70000的員工:\")\n",
    "high_salary_df = employees_df.filter(col(\"salary\") > 70000)\n",
    "high_salary_df.show()\n",
    "\n",
    "print(\"\\n工程部門的員工:\")\n",
    "engineering_df = employees_df.filter(col(\"department\") == \"Engineering\")\n",
    "engineering_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 複合條件過濾\n",
    "print(\"工程部門且薪水大於75000的員工:\")\n",
    "complex_filter_df = employees_df.filter(\n",
    "    (col(\"department\") == \"Engineering\") & (col(\"salary\") > 75000)\n",
    ")\n",
    "complex_filter_df.show()\n",
    "\n",
    "print(\"\\n年齡在25-30歲之間的員工:\")\n",
    "age_range_df = employees_df.filter(\n",
    "    (col(\"age\") >= 25) & (col(\"age\") <= 30)\n",
    ")\n",
    "age_range_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 添加和修改列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 添加新列\n",
    "employees_with_bonus = employees_df.withColumn(\n",
    "    \"bonus\", col(\"salary\") * 0.1\n",
    ")\n",
    "\n",
    "print(\"添加獎金列:\")\n",
    "employees_with_bonus.select(\"name\", \"salary\", \"bonus\").show()\n",
    "\n",
    "# 添加年薪列\n",
    "employees_with_annual = employees_with_bonus.withColumn(\n",
    "    \"annual_salary\", col(\"salary\") * 12\n",
    ")\n",
    "\n",
    "print(\"\\n添加年薪列:\")\n",
    "employees_with_annual.select(\"name\", \"salary\", \"annual_salary\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 條件列\n",
    "employees_with_level = employees_df.withColumn(\n",
    "    \"level\",\n",
    "    when(col(\"salary\") >= 80000, \"Senior\")\n",
    "    .when(col(\"salary\") >= 65000, \"Mid\")\n",
    "    .otherwise(\"Junior\")\n",
    ")\n",
    "\n",
    "print(\"員工等級:\")\n",
    "employees_with_level.select(\"name\", \"salary\", \"level\").show()\n",
    "\n",
    "# 年齡組分類\n",
    "employees_with_age_group = employees_with_level.withColumn(\n",
    "    \"age_group\",\n",
    "    when(col(\"age\") < 28, \"Young\")\n",
    "    .when(col(\"age\") < 32, \"Middle\")\n",
    "    .otherwise(\"Senior\")\n",
    ")\n",
    "\n",
    "print(\"\\n年齡組分類:\")\n",
    "employees_with_age_group.select(\"name\", \"age\", \"age_group\", \"level\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 分組和聚合操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按部門分組統計\n",
    "dept_stats = employees_df.groupBy(\"department\").agg(\n",
    "    count(\"*\").alias(\"employee_count\"),\n",
    "    avg(\"salary\").alias(\"avg_salary\"),\n",
    "    spark_max(\"salary\").alias(\"max_salary\"),\n",
    "    spark_min(\"salary\").alias(\"min_salary\"),\n",
    "    spark_sum(\"salary\").alias(\"total_salary\")\n",
    ")\n",
    "\n",
    "print(\"部門統計:\")\n",
    "dept_stats.show()\n",
    "\n",
    "# 按年齡組分組\n",
    "age_group_stats = employees_with_age_group.groupBy(\"age_group\").agg(\n",
    "    count(\"*\").alias(\"count\"),\n",
    "    avg(\"salary\").alias(\"avg_salary\")\n",
    ")\n",
    "\n",
    "print(\"\\n年齡組統計:\")\n",
    "age_group_stats.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 多維度分組\n",
    "dept_level_stats = employees_with_level.groupBy(\"department\", \"level\").agg(\n",
    "    count(\"*\").alias(\"count\"),\n",
    "    avg(\"salary\").alias(\"avg_salary\")\n",
    ")\n",
    "\n",
    "print(\"部門和等級統計:\")\n",
    "dept_level_stats.orderBy(\"department\", \"level\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 排序操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按薪水排序\n",
    "print(\"按薪水升序排序:\")\n",
    "employees_df.orderBy(\"salary\").show()\n",
    "\n",
    "print(\"\\n按薪水降序排序:\")\n",
    "employees_df.orderBy(col(\"salary\").desc()).show()\n",
    "\n",
    "# 多列排序\n",
    "print(\"\\n按部門和薪水排序:\")\n",
    "employees_df.orderBy(\"department\", col(\"salary\").desc()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 字符串操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 字符串轉換\n",
    "string_ops_df = employees_df.select(\n",
    "    \"name\",\n",
    "    upper(col(\"name\")).alias(\"name_upper\"),\n",
    "    lower(col(\"name\")).alias(\"name_lower\"),\n",
    "    substring(col(\"name\"), 1, 3).alias(\"name_substr\"),\n",
    "    concat(col(\"name\"), lit(\" - \"), col(\"department\")).alias(\"name_dept\")\n",
    ")\n",
    "\n",
    "print(\"字符串操作:\")\n",
    "string_ops_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 連接操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 創建部門資料\n",
    "dept_data = [\n",
    "    (\"Engineering\", \"Tech\", \"Building A\"),\n",
    "    (\"Sales\", \"Business\", \"Building B\"),\n",
    "    (\"Marketing\", \"Business\", \"Building C\"),\n",
    "    (\"HR\", \"Support\", \"Building D\")\n",
    "]\n",
    "\n",
    "dept_df = spark.createDataFrame(dept_data, [\"department\", \"division\", \"location\"])\n",
    "\n",
    "print(\"部門資料:\")\n",
    "dept_df.show()\n",
    "\n",
    "# Inner Join\n",
    "print(\"\\n員工和部門資料連接:\")\n",
    "joined_df = employees_df.join(dept_df, \"department\")\n",
    "joined_df.select(\"name\", \"department\", \"division\", \"location\", \"salary\").show()\n",
    "\n",
    "# Left Join\n",
    "print(\"\\n左連接 (保留所有員工):\")\n",
    "left_joined_df = employees_df.join(dept_df, \"department\", \"left\")\n",
    "left_joined_df.select(\"name\", \"department\", \"division\", \"location\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 視窗函數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number, rank, dense_rank, lag, lead\n",
    "\n",
    "# 定義視窗規格\n",
    "window_spec = Window.partitionBy(\"department\").orderBy(col(\"salary\").desc())\n",
    "\n",
    "# 添加排名\n",
    "ranked_df = employees_df.withColumn(\n",
    "    \"rank\", rank().over(window_spec)\n",
    ").withColumn(\n",
    "    \"dense_rank\", dense_rank().over(window_spec)\n",
    ").withColumn(\n",
    "    \"row_number\", row_number().over(window_spec)\n",
    ")\n",
    "\n",
    "print(\"部門內薪水排名:\")\n",
    "ranked_df.select(\"name\", \"department\", \"salary\", \"rank\", \"dense_rank\", \"row_number\").show()\n",
    "\n",
    "# 找出每個部門薪水最高的員工\n",
    "top_earners = ranked_df.filter(col(\"rank\") == 1)\n",
    "print(\"\\n每個部門薪水最高的員工:\")\n",
    "top_earners.select(\"name\", \"department\", \"salary\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 缺失值處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 創建包含缺失值的數據\n",
    "data_with_nulls = [\n",
    "    (\"Alice\", 25, \"Engineering\", 75000),\n",
    "    (\"Bob\", None, \"Sales\", 65000),\n",
    "    (\"Charlie\", 35, None, 85000),\n",
    "    (\"Diana\", 28, \"Marketing\", None),\n",
    "    (None, 32, \"Engineering\", 80000)\n",
    "]\n",
    "\n",
    "df_with_nulls = spark.createDataFrame(data_with_nulls, [\"name\", \"age\", \"department\", \"salary\"])\n",
    "\n",
    "print(\"包含缺失值的數據:\")\n",
    "df_with_nulls.show()\n",
    "\n",
    "# 檢查缺失值\n",
    "print(\"\\n各列缺失值統計:\")\n",
    "for col_name in df_with_nulls.columns:\n",
    "    null_count = df_with_nulls.filter(col(col_name).isNull()).count()\n",
    "    total_count = df_with_nulls.count()\n",
    "    print(f\"{col_name}: {null_count} / {total_count} ({null_count/total_count*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 刪除包含缺失值的行\n",
    "print(\"刪除包含缺失值的行:\")\n",
    "df_dropped = df_with_nulls.dropna()\n",
    "df_dropped.show()\n",
    "\n",
    "# 填充缺失值\n",
    "print(\"\\n填充缺失值:\")\n",
    "df_filled = df_with_nulls.fillna({\n",
    "    \"name\": \"Unknown\",\n",
    "    \"age\": 30,\n",
    "    \"department\": \"Unknown\",\n",
    "    \"salary\": 50000\n",
    "})\n",
    "df_filled.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. 資料類型轉換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 檢查當前資料類型\n",
    "print(\"當前資料類型:\")\n",
    "employees_df.printSchema()\n",
    "\n",
    "# 轉換資料類型\n",
    "converted_df = employees_df.withColumn(\n",
    "    \"salary_str\", col(\"salary\").cast(\"string\")\n",
    ").withColumn(\n",
    "    \"age_double\", col(\"age\").cast(\"double\")\n",
    ")\n",
    "\n",
    "print(\"\\n轉換後的資料類型:\")\n",
    "converted_df.printSchema()\n",
    "\n",
    "# 顯示轉換結果\n",
    "converted_df.select(\"name\", \"salary\", \"salary_str\", \"age\", \"age_double\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. 執行計劃分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看執行計劃\n",
    "complex_query = employees_df.filter(col(\"salary\") > 70000) \\\n",
    "                           .groupBy(\"department\") \\\n",
    "                           .agg(avg(\"salary\").alias(\"avg_salary\")) \\\n",
    "                           .orderBy(col(\"avg_salary\").desc())\n",
    "\n",
    "print(\"執行計劃:\")\n",
    "complex_query.explain()\n",
    "\n",
    "print(\"\\n詳細執行計劃:\")\n",
    "complex_query.explain(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. 緩存和持久化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 緩存 DataFrame\n",
    "cached_df = employees_df.cache()\n",
    "\n",
    "# 觸發緩存\n",
    "print(\"觸發緩存操作:\")\n",
    "print(f\"總員工數: {cached_df.count()}\")\n",
    "print(f\"平均薪水: {cached_df.agg(avg('salary')).collect()[0][0]:.2f}\")\n",
    "\n",
    "# 檢查緩存狀態\n",
    "print(f\"\\n是否已緩存: {cached_df.is_cached}\")\n",
    "\n",
    "# 取消緩存\n",
    "cached_df.unpersist()\n",
    "print(f\"取消緩存後: {cached_df.is_cached}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. 實戰練習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 練習1：員工薪水分析\n",
    "分析員工薪水分佈，找出薪水異常值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 計算薪水統計\n",
    "salary_stats = employees_df.agg(\n",
    "    avg(\"salary\").alias(\"avg_salary\"),\n",
    "    spark_max(\"salary\").alias(\"max_salary\"),\n",
    "    spark_min(\"salary\").alias(\"min_salary\")\n",
    ").collect()[0]\n",
    "\n",
    "print(\"薪水統計:\")\n",
    "print(f\"平均薪水: ${salary_stats['avg_salary']:,.2f}\")\n",
    "print(f\"最高薪水: ${salary_stats['max_salary']:,.2f}\")\n",
    "print(f\"最低薪水: ${salary_stats['min_salary']:,.2f}\")\n",
    "\n",
    "# 找出薪水異常值（高於平均薪水 1.5 倍的員工）\n",
    "avg_salary = salary_stats['avg_salary']\n",
    "outliers = employees_df.filter(col(\"salary\") > avg_salary * 1.5)\n",
    "\n",
    "print(\"\\n薪水異常值員工:\")\n",
    "outliers.select(\"name\", \"department\", \"salary\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 練習2：部門薪水差異分析\n",
    "分析不同部門之間的薪水差異"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 計算部門薪水統計\n",
    "dept_salary_analysis = employees_df.groupBy(\"department\").agg(\n",
    "    count(\"*\").alias(\"employee_count\"),\n",
    "    avg(\"salary\").alias(\"avg_salary\"),\n",
    "    spark_max(\"salary\").alias(\"max_salary\"),\n",
    "    spark_min(\"salary\").alias(\"min_salary\"),\n",
    "    (spark_max(\"salary\") - spark_min(\"salary\")).alias(\"salary_range\")\n",
    ")\n",
    "\n",
    "print(\"部門薪水分析:\")\n",
    "dept_salary_analysis.orderBy(col(\"avg_salary\").desc()).show()\n",
    "\n",
    "# 找出薪水範圍最大的部門\n",
    "max_range_dept = dept_salary_analysis.orderBy(col(\"salary_range\").desc()).first()\n",
    "print(f\"\\n薪水範圍最大的部門: {max_range_dept['department']} (${max_range_dept['salary_range']:,.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 練習3：年齡與薪水關係分析\n",
    "分析年齡與薪水之間的關係"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 創建年齡組\n",
    "age_salary_analysis = employees_df.withColumn(\n",
    "    \"age_group\",\n",
    "    when(col(\"age\") < 28, \"20-27\")\n",
    "    .when(col(\"age\") < 32, \"28-31\")\n",
    "    .otherwise(\"32+\")\n",
    ").groupBy(\"age_group\").agg(\n",
    "    count(\"*\").alias(\"count\"),\n",
    "    avg(\"salary\").alias(\"avg_salary\"),\n",
    "    avg(\"age\").alias(\"avg_age\")\n",
    ")\n",
    "\n",
    "print(\"年齡組薪水分析:\")\n",
    "age_salary_analysis.orderBy(\"avg_age\").show()\n",
    "\n",
    "# 計算年齡與薪水的相關性（簡化版）\n",
    "age_salary_corr = employees_df.select(\"age\", \"salary\").rdd.map(\n",
    "    lambda row: (row.age, row.salary)\n",
    ").collect()\n",
    "\n",
    "ages = [x[0] for x in age_salary_corr]\n",
    "salaries = [x[1] for x in age_salary_corr]\n",
    "\n",
    "# 簡單的相關性計算\n",
    "import numpy as np\n",
    "correlation = np.corrcoef(ages, salaries)[0,1]\n",
    "print(f\"\\n年齡與薪水的相關係數: {correlation:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. 總結和清理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 顯示最終統計\n",
    "print(\"=== DataFrame 操作學習總結 ===\")\n",
    "print(f\"總員工數: {employees_df.count()}\")\n",
    "print(f\"部門數: {employees_df.select('department').distinct().count()}\")\n",
    "print(f\"薪水範圍: ${employees_df.agg(spark_min('salary')).collect()[0][0]:,} - ${employees_df.agg(spark_max('salary')).collect()[0][0]:,}\")\n",
    "print(f\"平均薪水: ${employees_df.agg(avg('salary')).collect()[0][0]:,.2f}\")\n",
    "\n",
    "# 停止 SparkSession\n",
    "spark.stop()\n",
    "print(\"\\nSpark session 已停止\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 學習重點回顧\n",
    "\n",
    "1. **DataFrame 基本操作**：select, filter, withColumn, groupBy, orderBy\n",
    "2. **聚合函數**：count, sum, avg, max, min\n",
    "3. **字符串操作**：upper, lower, substring, concat\n",
    "4. **條件操作**：when, otherwise\n",
    "5. **連接操作**：inner join, left join, right join\n",
    "6. **視窗函數**：rank, dense_rank, row_number\n",
    "7. **缺失值處理**：dropna, fillna\n",
    "8. **資料類型轉換**：cast\n",
    "9. **性能優化**：cache, explain\n",
    "10. **實戰分析**：薪水分析、部門比較、相關性分析\n",
    "\n",
    "通過這些練習，您已經掌握了 DataFrame 的核心操作，可以進行各種數據分析任務。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}